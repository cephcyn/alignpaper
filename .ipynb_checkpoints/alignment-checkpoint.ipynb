{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Documentation page](https://github.com/cephcyn/alignpaper/blob/master/documentation/muitiple_alignment.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "\n",
    "# Load fasttext-wiki-news-subwords-300 pretrained model\n",
    "fasttext = gensim.models.keyedvectors.FastTextKeyedVectors.load('model/fasttext-wiki-news-subwords-300.model', mmap='r')\n",
    "\n",
    "# # Load word2vec-google-news-300 pretrained model\n",
    "# word2vec = gensim.models.KeyedVectors.load('model/word2vec-google-news-300.model', mmap='r')\n",
    "\n",
    "import spacy\n",
    "\n",
    "sp = spacy.load('en_core_web_sm')\n",
    "\n",
    "import scispacy\n",
    "from scispacy.linking import EntityLinker\n",
    "\n",
    "scisp = spacy.load('en_core_sci_sm')\n",
    "linker = scisp.add_pipe('scispacy_linker', config={'resolve_abbreviations': True, 'linker_name': 'umls'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# Get the embedding of a phrase\n",
    "def get_phrase_embed(embed_model, phrase, remove_label=False, norm_zero_threshold=0.000000001):\n",
    "    # split the phrase into tokens to pass into the embed model\n",
    "    try:\n",
    "        phraseS = phrase.split()\n",
    "    except:\n",
    "        return pd.DataFrame()\n",
    "    # TODO remove stopwords?\n",
    "    # retrieve the embeddings of each token in the phrase\n",
    "    unknowns = []\n",
    "    emb = []\n",
    "    for w in phraseS:\n",
    "        try:\n",
    "            emb.append(embed_model[w])\n",
    "        except:\n",
    "            unknowns.append(w)\n",
    "    # normalize each embed so that it has a norm of 1\n",
    "    emb_normalized = []\n",
    "    for i in range(len(emb)):\n",
    "        e = emb[i]\n",
    "        e_norm = np.linalg.norm(e)\n",
    "        if e_norm < norm_zero_threshold:\n",
    "            warnings.warn(f'embed vector for word \\'{phraseS[i]}\\' with extremely low norm value')\n",
    "        emb_normalized.append(e / e_norm)\n",
    "    emb = emb_normalized\n",
    "    # if there are no recognized tokens in the phrase, return empty (same as non-splittable phrase)\n",
    "    if len(emb) == 0:\n",
    "        return pd.DataFrame()\n",
    "    # Average the embeds for tokens which have embeds\n",
    "    emb_avg = pd.DataFrame(emb).sum() / len(emb)\n",
    "    if not remove_label:\n",
    "        emb_avg['word'] = phrase\n",
    "    return pd.DataFrame([emb_avg])\n",
    "\n",
    "# get_phrase_embed(\n",
    "#     word2vec, \n",
    "#     'test sentence')\n",
    "# get_phrase_embed(\n",
    "#     word2vec, \n",
    "#     'This is a test sentence !')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import sample dataset\n",
    "(The code to construct the file `temp/ebm-pio_consegments.hdf` is in analyze.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import the data we've already constructed out of constituency parse of specific phrases in specific sentences\n",
    "con_segments = pd.read_hdf(f'temp/ebm-pio_consegments.hdf','mydata')\n",
    "con_segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform that data into the format that is more readable for alignment\n",
    "# (sorry, this is sort of an abuse of DataFrame datatypes)\n",
    "\n",
    "def transformTuples(row):\n",
    "    # turn each row into the segment tuples used for alignment\n",
    "    output = pd.DataFrame()\n",
    "    for i in range(len(row['alignsegments'])):\n",
    "        output[f'txt{i}'] = [(row['alignsegments'][i], row['aligntypes'][i], row['alignctypes'][i])]\n",
    "    return output.set_index(pd.Series([row.name]))\n",
    "\n",
    "transformTuples(con_segments.loc[7298])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# alignment_df = con_segments.groupby(con_segments.index, group_keys=False).apply(\n",
    "#     lambda group: transformTuples(group.iloc[0]))\n",
    "# alignment_df = alignment_df.applymap(lambda x: ('', '', []) if x is np.nan else x)\n",
    "# alignment_df.to_hdf(f'temp/ebm-pio_consegments-alignformat.hdf', 'mydata', mode='w')\n",
    "alignment_df = pd.read_hdf(f'temp/ebm-pio_consegments-alignformat.hdf','mydata')\n",
    "alignment_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitAlignTuples(row, split_token=' '):\n",
    "    # take each row of alignment tuples and split them on the split token\n",
    "    output = pd.DataFrame()\n",
    "    # extract the data we're going to use\n",
    "    tokens = ' '.join(row.map(lambda x: x[0])).split()\n",
    "    cpos = [e for sublist in list(row.map(lambda x: x[2])) for e in sublist]\n",
    "    output_row = list(zip(tokens, cpos, [[e] for e in cpos]))\n",
    "    for i in range(len(tokens)):\n",
    "        output[f'txt{i}'] = [output_row[i]]\n",
    "    return output.set_index(pd.Series([row.name]))\n",
    "\n",
    "splitAlignTuples(alignment_df.loc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# alignment_df_tseg = alignment_df.groupby(alignment_df.index, group_keys=False).apply(\n",
    "#     lambda group: splitAlignTuples(group.iloc[0]))\n",
    "# alignment_df_tseg = alignment_df_tseg.applymap(lambda x: ('', '', []) if x is np.nan else x)\n",
    "# alignment_df_tseg.to_hdf(f'temp/ebm-pio_tseg-alignformat.hdf', 'mydata', mode='w')\n",
    "alignment_df_tseg = pd.read_hdf(f'temp/ebm-pio_tseg-alignformat.hdf','mydata')\n",
    "alignment_df_tseg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse file or string into alignment DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "def sheetstring_to_alignment(alignment_text):\n",
    "    data_start = 4\n",
    "    nonpos_characters = [' ', '\\'', '[', ']']\n",
    "    rows = {}\n",
    "    alignment_text = alignment_text.split('\\n')\n",
    "    # fill in actual data\n",
    "    for line in alignment_text:\n",
    "        cells = line.split('\\t')\n",
    "        if cells[2] == 's-txt':\n",
    "            # input the text data\n",
    "            if cells[0] not in rows:\n",
    "                rows[cells[0]] = [('','',[])]*len(cells[data_start:])\n",
    "            for i in range(min(len(cells[data_start:]), len(rows[cells[0]]))):\n",
    "                prev_tuple = rows[cells[0]][i]\n",
    "                rows[cells[0]][i] = (cells[data_start+i].strip(), prev_tuple[1], prev_tuple[2])\n",
    "        elif cells[2] == 's-pos':\n",
    "            # input the token pos data\n",
    "            if cells[0] not in rows:\n",
    "                rows[cells[0]] = [('','',[])]*len(cells[data_start:])\n",
    "            for i in range(min(len(cells[data_start:]), len(rows[cells[0]]))):\n",
    "                prev_tuple = rows[cells[0]][i]\n",
    "                cell_pos = ast.literal_eval(cells[data_start+i]) if len(cells[data_start+i])>0 else []\n",
    "                cell_pos = [pos for pos in cell_pos if pos!='']\n",
    "                rows[cells[0]][i] = (prev_tuple[0], prev_tuple[1], cell_pos)\n",
    "        elif cells[2] == 's-ppos':\n",
    "            if cells[0] not in rows:\n",
    "                rows[cells[0]] = [('','',[])]*len(cells[data_start:])\n",
    "            for i in range(min(len(cells[data_start:]), len(rows[cells[0]]))):\n",
    "                prev_tuple = rows[cells[0]][i]\n",
    "                rows[cells[0]][i] = (prev_tuple[0], cells[data_start+i].strip(), prev_tuple[2])\n",
    "    # fill in the blank cells\n",
    "    output_width = max([len(r) for r in rows.values()])\n",
    "    for k in rows:\n",
    "        for i in range(output_width - len(rows[k])):\n",
    "            rows[k] = rows[k] + [('','',[])]\n",
    "    output_df = pd.DataFrame(rows.values(), index=rows.keys())\n",
    "    output_df.columns = [f'txt{i}' for i in range(len(output_df.columns))]\n",
    "    return output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_alignment_from_sheetstring_file(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        file = f.read()\n",
    "    file = file.splitlines()\n",
    "    input_alignment_text = '\\n'.join(file)\n",
    "    align_df = sheetstring_to_alignment(input_alignment_text)\n",
    "    return align_df\n",
    "\n",
    "# read_alignment_from_sheetstring_file('testcases/basic-colcreat-005-relation/a.alignment')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse JSONable dict format into alignment DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jsondict_to_alignment(alignment_dict):\n",
    "    rows = {}\n",
    "    for row in alignment_dict['alignment']:\n",
    "        rows[row['id']] = [\n",
    "            (\n",
    "                ' '.join(row['txt'][i]) if ('txt' in row) else '',\n",
    "                ' '.join(row['ppos'][i]) if ('ppos' in row) else '', # TODO haven't nailed down format... phrasePOS is hardly used\n",
    "                row['pos'][i] if ('pos' in row) else []\n",
    "            ) \n",
    "            for i in range(len(row['txt']))\n",
    "        ]\n",
    "    output_df = pd.DataFrame(rows.values(), index=rows.keys())\n",
    "    output_df.columns = [f'txt{i}' for i in range(len(output_df.columns))]\n",
    "    return output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def read_alignment_from_jsondict_file(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        jsonfile = json.load(f)\n",
    "    align_df = jsondict_to_alignment(jsonfile)\n",
    "    return align_df\n",
    "\n",
    "# read_alignment_from_jsondict_file('testcases/basic-colcreat-005-relation/a.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse alignment DF into JSONable dict format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alignment_to_jsondict(alignment_df):\n",
    "    rows = []\n",
    "    for index, row in alignment_df.iterrows():\n",
    "        row_obj = {}\n",
    "        row_obj['id'] = index\n",
    "        row_obj['pos'] = []\n",
    "        row_obj['txt'] = []\n",
    "        for col in row:\n",
    "            row_obj['pos'].append(col[2])\n",
    "            row_obj['txt'].append([e for e in col[0].split(' ') if (e != '')])\n",
    "        rows.append(row_obj)\n",
    "    return {'alignment':rows}\n",
    "\n",
    "# alignment_to_json(read_alignment_from_jsondict_file('testcases/basic-colcreat-005-relation/a.json'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alignment operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def mergeAdjacentNP(row):\n",
    "#     # merge adjacent noun phrases\n",
    "#     # TODO adapt this for alignment df format!!!\n",
    "#     # TODO fix the deep copy bug\n",
    "#     output = row.copy()\n",
    "#     for i in reversed(range(len(output['alignsegments'])-1)):\n",
    "#         if output['aligntypes'][i]=='NP' and output['aligntypes'][i+1]=='NP':\n",
    "#             output['alignsegments'][i] += ' ' + output['alignsegments'][i+1]\n",
    "#             output['alignsegments'][i+1] = []\n",
    "#             output['aligntypes'][i+1] = []\n",
    "#             output['alignctypes'][i] += output['alignctypes'][i+1]\n",
    "#             output['alignctypes'][i+1] = []\n",
    "#     output = output.drop('aligntup')\n",
    "#     output['alignsegments'] = [e for e in output['alignsegments'] if e != []]\n",
    "#     output['aligntypes'] = [e for e in output['aligntypes'] if e != []]\n",
    "#     output['alignctypes'] = [[e for i in e] for e in output['alignctypes'] if e != []]\n",
    "#     return output\n",
    "\n",
    "# temp_df = con_segments\n",
    "# temp_df = temp_df.apply(\n",
    "#     lambda row: mergeAdjacentNP(row), \n",
    "#     axis=1, result_type='expand')\n",
    "# temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TODO this is still buggy, don't use it\n",
    "# def mergeParentheses(row):\n",
    "#     # merge parenthetical clauses\n",
    "#     numOpenParens = 0\n",
    "#     lastStart = -1\n",
    "#     mergeSegments = []\n",
    "#     for i in range(len(row['alignsegments'])):\n",
    "#         for c in [c for c in row['alignsegments'][i] if c in ['(', ')']]:\n",
    "#             if c == '(':\n",
    "#                 numOpenParens += 1\n",
    "#                 if numOpenParens == 1:\n",
    "#                     lastStart = i\n",
    "#             else:\n",
    "#                 numOpenParens -= 1\n",
    "#                 if numOpenParens == 0 and lastStart != i:\n",
    "#                     # close the parentheses\n",
    "#                     mergeSegments.append((lastStart, i))\n",
    "#     if numOpenParens > 0:\n",
    "#         mergeSegments.append((lastStart, len(row['alignsegments'])))\n",
    "#     mergeSegments = list(set(mergeSegments))\n",
    "#     if mergeSegments != []:\n",
    "#         for t in reversed(mergeSegments):\n",
    "#             print(row['aligntypes'][t[0]:t[1]+1])\n",
    "#             print(row['alignsegments'][t[0]:t[1]+1])\n",
    "#         print()\n",
    "#     return row\n",
    "\n",
    "# temp_df = con_segments\n",
    "# temp_df.apply(\n",
    "#     lambda row: mergeParentheses(row), \n",
    "#     axis=1, result_type='expand')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractTup(data, tup_i=0, is_frame=True):\n",
    "    types = {\n",
    "        'segment': 0,\n",
    "        'pos': 1,\n",
    "        'cpos': 2\n",
    "    }\n",
    "    if tup_i in types:\n",
    "        tup_i = types[tup_i]\n",
    "    else:\n",
    "        raise ValueError(f'tup_i not in types: {types.keys()}')\n",
    "    if is_frame:\n",
    "        return data.applymap(lambda x: x[tup_i])\n",
    "    else:\n",
    "        return data.map(lambda x: x[tup_i])\n",
    "\n",
    "# extractTup(transformTuples(temp_df.loc[7298]), tup_i='segment', is_frame=True)\n",
    "extractTup(alignment_df.loc[[7298]], tup_i='segment', is_frame=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeEmptyColumns(align_df):\n",
    "    output_columns = []\n",
    "    for c in align_df.columns:\n",
    "        align_df_c = extractTup(align_df.loc[:, c], tup_i='segment', is_frame=False)\n",
    "        if len([e for e in align_df_c if e.strip() != '']) != 0:\n",
    "            output_columns.append(c)\n",
    "    output_df = align_df[output_columns]\n",
    "    output_df.columns = [f'txt{i}' for i in range(len(output_df.columns))]\n",
    "    return output_df\n",
    "removeEmptyColumns(alignment_df.loc[[7298, 7321]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create alignment\n",
    "[alignRowMajorLocal documentation / pseudocode](https://github.com/cephcyn/alignpaper/blob/master/documentation/multiple_alignment.md#alignRowMajorLocal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from nltk.metrics import edit_distance\n",
    "\n",
    "def alignRowMajorLocal(align_a, align_b, use_types=False, remove_empty_cols=True, embed_model=fasttext, debug_print=False):\n",
    "    # An implementation of Smith-Waterman alignment\n",
    "    # RETURNS:\n",
    "    #  1. The alignment DataFrame\n",
    "    #  2. The score associated with this alignment\n",
    "    if remove_empty_cols:\n",
    "        align_a = removeEmptyColumns(align_a)\n",
    "        align_b = removeEmptyColumns(align_b)\n",
    "    align_a_segment = extractTup(align_a, tup_i='segment')\n",
    "    align_b_segment = extractTup(align_b, tup_i='segment')\n",
    "    align_a_type = extractTup(align_a, tup_i='pos')\n",
    "    align_b_type = extractTup(align_b, tup_i='pos')\n",
    "    align_a_ctype = extractTup(align_a, tup_i='cpos')\n",
    "    align_b_ctype = extractTup(align_b, tup_i='cpos')\n",
    "    # Doing a general alignment\n",
    "    align_a_elems = [i for i in range(len(align_a.columns))]\n",
    "    align_b_elems = [i for i in range(len(align_b.columns))]\n",
    "    if debug_print:\n",
    "        print(align_a_elems)\n",
    "        print(align_b_elems)\n",
    "        print()\n",
    "    def getScoreAligningIndices(index_a, index_b, embed_model):\n",
    "        # A higher score is better / more match!\n",
    "        # make sure all the segment texts are precomputed lol\n",
    "        text_a = list(align_a_segment[align_a.columns[index_a]])\n",
    "        text_b = list(align_b_segment[align_b.columns[index_b]])\n",
    "        # TODO clean up this embed checking thing and remove the need for cached_phrase_embeds\n",
    "        # TODO also unify this with the col embed variation measure somehow?\n",
    "        cached_phrase_embeds = {}\n",
    "        for text in text_a+text_b:\n",
    "            if text not in cached_phrase_embeds:\n",
    "                try:\n",
    "                    cached_phrase_embeds[text] = get_phrase_embed(embed_model, text).drop('word', 1)\n",
    "                except KeyError:\n",
    "                    pass\n",
    "        # start off with phrase embedding distance (current max is 60 for perfect match)\n",
    "        # if we have embeds for any word in each set, ignore others and just use words we have embeds for\n",
    "        if any(s in cached_phrase_embeds for s in text_a)\\\n",
    "                and any(s in cached_phrase_embeds for s in text_b):\n",
    "            # calculate overall embeds\n",
    "            embed_a = pd.concat([cached_phrase_embeds[text] for text\n",
    "                                 in text_a if text in cached_phrase_embeds]).apply(lambda x: x.mean())\n",
    "            embed_b = pd.concat([cached_phrase_embeds[text] for text\n",
    "                                 in text_b if text in cached_phrase_embeds]).apply(lambda x: x.mean())\n",
    "            # TODO can tweak this scoring calculation a little for performance\n",
    "            score = 10 * (6 - np.linalg.norm(embed_a-embed_b))\n",
    "        else:\n",
    "            # use levenshtein dist as fallback... if either set has NO words with embeds available\n",
    "            scaled_edits_sum = 0\n",
    "            for phrase_a in [p for p in text_a if len(p) != 0]:\n",
    "                for phrase_b in [p for p in text_b if len(p) != 0]:\n",
    "                    scaled_edits_sum += edit_distance(phrase_a,phrase_b) / max(len(phrase_a), len(phrase_b))\n",
    "            score = 60 * (1 - (scaled_edits_sum / (len(text_a) * len(text_b))))\n",
    "        # add a component based on phrase type if that flag is set\n",
    "        # TODO improve this?; this currently just returns -inf if mismatch of type sets\n",
    "        # Might want to add support for aligning different types of phrase together...\n",
    "        if use_types:\n",
    "            # reduce to set\n",
    "            types_a = set([t for t in align_a_type[align_a.columns[index_a]] if t.strip() != ''])\n",
    "            types_b = set([t for t in align_b_type[align_b.columns[index_b]] if t.strip() != ''])\n",
    "#             # check if we are handling a hard pos match\n",
    "#             if any([((p in types_a) or (p in types_b)) for p in pos_must_match]):\n",
    "            if len(types_a) != 0 and len(types_b) != 0 and types_a != types_b:\n",
    "                score = -1 * math.inf\n",
    "        # TODO: add a component based on phrase ctype (phrase POS breakdown) (?)\n",
    "        if debug_print:\n",
    "            print(f'scoring between '\n",
    "                  +f'\"{list(align_a_segment[align_a.columns[index_a]])}\" and '\n",
    "                  +f'\"{list(align_b_segment[align_b.columns[index_b]])}\": {score}')\n",
    "        return score\n",
    "    def getGapPenalty(length, size=1):\n",
    "        return -1 * (1 * min(length,1) + 0.1 * max(length-1,0)) #* (1 + math.log(size))\n",
    "    # Build score matrix of size (a-alignables + 1)x(b-alignables + 1)\n",
    "    scores = np.zeros((len(align_a_elems)+1, len(align_b_elems)+1))\n",
    "    # Build traceback matrix\n",
    "    # traceback = 0 for end, 4 for W, 7 for NW, 9 for N (to calculate traceback, t%2 is N-ness, t%3 is W-ness)\n",
    "    traceback = np.zeros((len(align_a_elems)+1, len(align_b_elems)+1))\n",
    "    # Iterate through all of the cells to populate both the score and traceback matrices\n",
    "    for i in range(1, scores.shape[0]):\n",
    "        for j in range(1, scores.shape[1]):\n",
    "            score_map = {}\n",
    "            # calculate score for aligning nouns a[i] and b[j]\n",
    "            score_map[\n",
    "                scores[i-1,j-1] + getScoreAligningIndices(align_a_elems[i-1], align_b_elems[j-1], embed_model)\n",
    "            ] = 7\n",
    "            # calculate score for gap in i\n",
    "            for i_gap in range(1, i):\n",
    "                igap_score = scores[i-i_gap,j] + getGapPenalty(i_gap, size=len(align_a_elems))\n",
    "                score_map[igap_score] = 9\n",
    "            # calculate score for gap in j\n",
    "            for j_gap in range(1, j):\n",
    "                jgap_score = scores[i,j-j_gap] + getGapPenalty(j_gap, size=len(align_b_elems))\n",
    "                score_map[jgap_score] = 4\n",
    "            # add the possibility for unrelatedness\n",
    "            score_map[0] = 0\n",
    "            scores[i,j] = max(score_map.keys())\n",
    "            traceback[i,j] = score_map[max(score_map.keys())]\n",
    "    if debug_print:\n",
    "        print()\n",
    "        print(scores)\n",
    "        print(traceback)\n",
    "        print()\n",
    "    # Do traceback to build our final alignment\n",
    "    tracepoint = np.unravel_index(np.argmax(scores, axis=None), scores.shape)\n",
    "    points_a = []\n",
    "    points_b = []\n",
    "    while traceback[tracepoint] != 0:\n",
    "        # contribute to the align information\n",
    "        if traceback[tracepoint] == 7:\n",
    "            # this is a point where two elements were aligned\n",
    "            points_a.append(align_a_elems[tracepoint[0]-1])\n",
    "            points_b.append(align_b_elems[tracepoint[1]-1])\n",
    "        elif traceback[tracepoint] == 4:\n",
    "            # this is a point where there was a gap inserted for row_a\n",
    "            points_a.append(-1)\n",
    "            points_b.append(align_b_elems[tracepoint[1]-1])\n",
    "        elif traceback[tracepoint] == 9:\n",
    "            # this is a point where there was a gap inserted for row_b\n",
    "            points_a.append(align_a_elems[tracepoint[0]-1])\n",
    "            points_b.append(-1)\n",
    "        # step backwards\n",
    "        tracepoint = (\n",
    "            tracepoint[0] - int(traceback[tracepoint] % 2),\n",
    "            tracepoint[1] - int(traceback[tracepoint] % 3))\n",
    "    points_a = list(reversed(points_a))\n",
    "    points_b = list(reversed(points_b))\n",
    "    if len(points_a) != len(points_b):\n",
    "        # enforce that align_a and align_b are the same length (they should be)\n",
    "        raise ValueError('should not occur; bug in S-W local alignment?')\n",
    "    if debug_print:\n",
    "        print(points_a)\n",
    "        print(points_b)\n",
    "        print()\n",
    "    # Create a nice neat form of this alignment\n",
    "    # TODO add support for NP-only alignment gaps?\n",
    "    range_a = [i for i in points_a if i >= 0]\n",
    "    range_b = [i for i in points_b if i >= 0]\n",
    "    range_a = (range_a[0], range_a[-1])\n",
    "    range_b = (range_b[0], range_b[-1])\n",
    "    output = pd.DataFrame(columns=[f'txt{i}' for i in range(\n",
    "        (range_a[0] + range_b[0]) + len(points_a)\n",
    "        + max(0, (len(align_a.columns) - range_a[1]) - 1)\n",
    "        + max(0, (len(align_b.columns) - range_b[1]) - 1)\n",
    "    )])\n",
    "    # build the segment from align_a\n",
    "    realign_a = align_a.loc[:, [f'txt{i}' for i in range(range_a[0])]]\n",
    "    for i in range(range_b[0]):\n",
    "        realign_a.insert(len(realign_a.columns), f'insx{i}', np.nan, True)\n",
    "    for i in points_a:\n",
    "        if i >= 0:\n",
    "            realign_a[align_a.columns[i]] = align_a.loc[:, align_a.columns[i]]\n",
    "        else:\n",
    "            realign_a.insert(len(realign_a.columns), f'ins{len(realign_a.columns)}', np.nan, True)\n",
    "    for i in range(range_a[1]+1, len(align_a.columns)):\n",
    "        realign_a[align_a.columns[i]] = align_a.loc[:, align_a.columns[i]]\n",
    "    for i in range(range_b[1]+1, len(align_b.columns)):\n",
    "        realign_a.insert(len(realign_a.columns), f'insx{i+range_b[0]}', np.nan, True)\n",
    "    # build the segment from align_b\n",
    "    realign_b = align_b.loc[:, [f'txt{i}' for i in range(range_b[0])]]\n",
    "    for i in range(range_a[0]):\n",
    "        realign_b.insert(0, f'insx{i}', np.nan, True)\n",
    "    for i in points_b:\n",
    "        if i >= 0:\n",
    "            realign_b[align_b.columns[i]] = align_b.loc[:, align_b.columns[i]]\n",
    "        else:\n",
    "            realign_b.insert(len(realign_b.columns), f'ins{len(realign_b.columns)}', np.nan, True)\n",
    "    for i in range(range_a[1]+1, len(align_a.columns)):\n",
    "        realign_b.insert(len(realign_b.columns), f'insx{i+range_a[0]}', np.nan, True)\n",
    "    for i in range(range_b[1]+1, len(align_b.columns)):\n",
    "        realign_b[align_b.columns[i]] = align_b.loc[:, align_b.columns[i]]\n",
    "    # build final output\n",
    "    realign_a.columns = output.columns\n",
    "    realign_b.columns = output.columns\n",
    "    output = output.append(realign_a)\n",
    "    output = output.append(realign_b)\n",
    "    return output.applymap(lambda x: ('', '', []) if x is np.nan else x), np.amax(scores, axis=None)\n",
    "\n",
    "# toy_align, toy_align_score = alignRowMajorLocal(\n",
    "#     alignment_df.loc[[7298]],\n",
    "#     alignment_df.loc[[7321]],\n",
    "#     remove_empty_cols=True)\n",
    "# print(toy_align_score)\n",
    "# toy_align\n",
    "\n",
    "# toy_align, toy_align_score = alignRowMajorLocal(\n",
    "#     alignment_df_tseg.loc[[7298]],\n",
    "#     alignment_df_tseg.loc[[7321]],\n",
    "#     remove_empty_cols=True, use_types=True)\n",
    "# print(toy_align_score)\n",
    "# toy_align"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# alignment_df_tseg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toy_align, toy_align_score = alignRowMajorLocal(\n",
    "    alignment_df_tseg.loc[[1021]],\n",
    "    alignment_df_tseg.loc[[1048]],\n",
    "    remove_empty_cols=True, use_types=False)\n",
    "print(toy_align_score)\n",
    "toy_align"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the toy data\n",
    "toy_tiny_data = pd.Series(\n",
    "    ['Asperger syndrome', \n",
    "     'high - functioning ASD', \n",
    "     'unrecognized and untreated anxiety', \n",
    "     'generalized anxiety disorders', \n",
    "     'anxiety', \n",
    "     'high - functioning autism spectrum disorders and anxiety', \n",
    "     'high - functioning ASD and anxiety', \n",
    "     'high - functioning ASD', \n",
    "     'high - functioning autism spectrum disorders', \n",
    "     'previously undetected anxiety', \n",
    "     'untreated anxiety']\n",
    ")\n",
    "# toy_tiny_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the toy data alignment\n",
    "toy_tiny_align = pd.DataFrame(toy_tiny_data.map(lambda x: (x, '', [] if len(x)==0 else [f'POS{e}' for e in range(len(x.split(' ')))])))\n",
    "toy_tiny_align = toy_tiny_align.rename(columns={0:'txt0'})\n",
    "toy_tiny_align = toy_tiny_align.set_index(toy_tiny_align.index.map(lambda x: str(x)))\n",
    "# toy_tiny_align"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column split step 1: Build word tree with node = word units running right->left\n",
    "\n",
    "# add text to the given trienode (edits the given tree_node)\n",
    "def wordTreeHelper(tree_node, text, id_data=None, right_align=False):\n",
    "    text = text.strip()\n",
    "    # Check for base case\n",
    "    if text == '':\n",
    "        tree_node[id_data] = id_data\n",
    "        return tree_node\n",
    "    # Select the right key\n",
    "    key = ''\n",
    "    if right_align:\n",
    "        key = text.split(' ')[-1]\n",
    "        text = ' '.join(text.split(' ')[0:-1])\n",
    "    else:\n",
    "        key = text.split(' ')[0]\n",
    "        text = ' '.join(text.split(' ')[1:])\n",
    "    # Put the key and text into the trie\n",
    "    if key not in tree_node:\n",
    "        tree_node[key] = {}\n",
    "    tree_node[key] = wordTreeHelper(tree_node[key], text, id_data=id_data, right_align=right_align)\n",
    "    return tree_node\n",
    "\n",
    "def wordTree(df, right_align=False):\n",
    "    tree = {}\n",
    "    for e_id in df.index:\n",
    "        tree = wordTreeHelper(tree, df.loc[e_id], id_data=e_id, right_align=right_align)\n",
    "    return tree\n",
    "\n",
    "st = wordTree(toy_tiny_data, 'txt')\n",
    "st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column split step 2a: Collapse the suffix trie (merge nodes with only one child)\n",
    "\n",
    "# edits the input trie\n",
    "def wordTreeCollapse(tree, right_align=False):\n",
    "    # Collapse children nodes first\n",
    "    added_keys = {}\n",
    "    removed_keys = []\n",
    "    for child in tree:\n",
    "        # if child maps to more nodes\n",
    "        if tree[child]!=child:\n",
    "            tree[child] = wordTreeCollapse(tree[child], right_align=right_align)\n",
    "            # Check if the new child node is collapsible\n",
    "            if len(tree[child]) == 1:\n",
    "                merge_key = list(tree[child])[0]\n",
    "                if tree[child][merge_key]!=merge_key:\n",
    "                    grandchild = list(tree[child])[0]\n",
    "                    grandchild_tree = tree[child][grandchild]\n",
    "                    # Perform the merge (put into edit queue)\n",
    "                    removed_keys.append(child)\n",
    "                    if right_align:\n",
    "                        added_keys[grandchild + ' ' + child] = grandchild_tree\n",
    "                    else:\n",
    "                        added_keys[child + ' ' + grandchild] = grandchild_tree\n",
    "    # Perform removals\n",
    "    for key in removed_keys:\n",
    "        tree.pop(key)\n",
    "    # Perform additions\n",
    "    for key in added_keys:\n",
    "        tree[key] = added_keys[key]\n",
    "    return tree\n",
    "\n",
    "st = wordTreeCollapse(st)\n",
    "st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column split step 2b: Compress the suffix trie to only two levels of depth.\n",
    "\n",
    "def wordTreeCompressHelper(tree_node, col_stack=[]):\n",
    "    updated_node = {}\n",
    "    for k in tree_node:\n",
    "        if k==tree_node[k]:\n",
    "            # if this reaches a leaf node\n",
    "            full_text = ' '.join(col_stack)\n",
    "            if full_text not in updated_node:\n",
    "                updated_node[full_text] = {}\n",
    "            updated_node[full_text][k]=k\n",
    "        else:\n",
    "            # if this is not a leaf node\n",
    "            sub_node = wordTreeCompressHelper(tree_node[k], col_stack+[k])\n",
    "            for sub_text in sub_node:\n",
    "                if sub_text not in updated_node:\n",
    "                    updated_node[sub_text] = {}\n",
    "                for sub_value in sub_node[sub_text]:\n",
    "                    updated_node[sub_text][sub_value] = sub_node[sub_text][sub_value]\n",
    "    return updated_node\n",
    "\n",
    "# edits the input trie\n",
    "def wordTreeCompress(tree, right_align=False):\n",
    "    for root in tree:\n",
    "        if root!=tree[root]:\n",
    "            # compress the 2nd level onwards into a single level!\n",
    "            compressed = wordTreeCompressHelper(tree[root])\n",
    "            # remove the empty string artifact from compresshelper\n",
    "            if '' in compressed:\n",
    "                for k in compressed['']:\n",
    "                    compressed[k] = compressed[''][k]\n",
    "                compressed.pop('')\n",
    "            tree[root] = compressed\n",
    "    return tree\n",
    "\n",
    "st = wordTreeCompress(st)\n",
    "st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column split step 3: Output the suffix trie to multiple columns\n",
    "\n",
    "# Calculate how many output columns we'll need\n",
    "# Get the depth of the trie (a trie with one terminal node {0:0} has depth 0)\n",
    "def wordTreeDepth(tree):\n",
    "    max_depth = 0\n",
    "    for child in tree:\n",
    "        if tree[child]!=child:\n",
    "            max_depth = max(max_depth, 1 + wordTreeDepth(tree[child]))\n",
    "    return max_depth\n",
    "\n",
    "def wordTreeSplit(tree, max_depth, output, so_far=[], right_align=False):\n",
    "    for child in tree:\n",
    "        if tree[child]==child:\n",
    "            # we have hit a base, put in an entry\n",
    "            if right_align:\n",
    "                output[child] = ['']*(max_depth - len(so_far)) + so_far\n",
    "            else:\n",
    "                output[child] = so_far + ['']*(max_depth - len(so_far))\n",
    "        else:\n",
    "            # this node has further children!\n",
    "            output = wordTreeSplit(\n",
    "                tree[child], \n",
    "                max_depth, \n",
    "                output, \n",
    "                ([child] + so_far) if right_align else (so_far + [child]), \n",
    "                right_align=right_align)\n",
    "    return output\n",
    "\n",
    "wordTreeSplit(st, wordTreeDepth(st), {}, right_align=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### split columns (word trie, unpolished)\n",
    "[splitCol documentation](https://github.com/cephcyn/alignpaper/blob/master/documentation/multiple_alignment.md#splitCol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitCol(src_alignment, split_col, right_align=False):\n",
    "    tree = wordTree(src_alignment[split_col].map(lambda x: x[0]), right_align=right_align)\n",
    "    tree = wordTreeCollapse(tree, right_align=right_align)\n",
    "    # squish that tree into only 2 levels because we only want to generate ONE new column max\n",
    "    tree = wordTreeCompress(tree)\n",
    "    tree_depth = wordTreeDepth(tree)\n",
    "    split_data = wordTreeSplit(tree, tree_depth, {}, right_align=right_align)\n",
    "    # TODO ... if we actually use this later, use the parse tree to determine merged phrase POS\n",
    "    pos_info = src_alignment[split_col].map(lambda x: x[2])\n",
    "    for k in split_data:\n",
    "        pos_i = 0\n",
    "        for i in range(len(split_data[k])):\n",
    "            chunk_text = split_data[k][i]\n",
    "            chunk_len = 0 if len(chunk_text)==0 else len(chunk_text.split(' '))\n",
    "            split_data[k][i] = (chunk_text, '', pos_info[k][pos_i:pos_i+chunk_len])\n",
    "            pos_i += chunk_len\n",
    "    split = pd.DataFrame(columns=[f'{split_col}-{i}' for i in range(tree_depth)])\n",
    "    for id in split_data:\n",
    "        split.loc[id] = split_data[id]\n",
    "    # combine the split results back into the rest of our original input data!\n",
    "    output = src_alignment.copy()\n",
    "    for i in range(len(split.columns)):\n",
    "        output.insert(output.columns.get_loc(split_col), f'{split_col}-{i}', split[split.columns[i]])\n",
    "    output = output.drop(split_col, 1)\n",
    "    output.columns = [f'txt{i}' for i in range(len(output.columns))]\n",
    "    return output\n",
    "    \n",
    "splitCol(toy_tiny_align, 'txt0', right_align=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Read in our manually created start alignment\n",
    "# align_df = read_alignment_from_sheetstring_file('interactive_input/alignment')\n",
    "\n",
    "# align_df\n",
    "# splitCol(align_df, 'txt20', right_align=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### merge columns\n",
    "[mergeCol documentation](https://github.com/cephcyn/alignpaper/blob/master/documentation/multiple_alignment.md#mergeCol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mergeCol(src_alignment, merge_col):\n",
    "    merge_col_next = src_alignment.columns[list(src_alignment.columns).index(merge_col)+1]\n",
    "    # combine the segment (text)\n",
    "    merged_segment = src_alignment[merge_col].map(lambda x: x[0]) + ' ' + src_alignment[merge_col_next].map(lambda x: x[0])\n",
    "    merged_segment = merged_segment.map(lambda x: x.strip())\n",
    "    # combine the pos (phrase pos)\n",
    "    merged_pos = src_alignment[merge_col].map(lambda x: x[1]) + ' ' + src_alignment[merge_col_next].map(lambda x: x[1])\n",
    "    merged_pos = merged_pos.map(lambda x: x.strip().split())\n",
    "    merged_pos = merged_pos.map(lambda x: '' if len(x)==0 else x[0]) # TODO ... if we actually use this later, use the parse tree to determine merged phrase POS\n",
    "    # combine the cpos (token / word pos)\n",
    "    merged_cpos = src_alignment[merge_col].map(lambda x: x[2]) + src_alignment[merge_col_next].map(lambda x: x[2])\n",
    "    # put the result column into our result\n",
    "    result = src_alignment.copy()\n",
    "    result[merge_col] = list(zip(merged_segment, merged_pos, merged_cpos))\n",
    "    del result[merge_col_next]\n",
    "    result.columns = [f'txt{i}' for i in range(len(result.columns))]\n",
    "    return result\n",
    "\n",
    "mergeCol(toy_align, 'txt0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def canShiftCells(src_alignment, shift_rows, shift_col, shift_distance, shift_size):\n",
    "    # remove duplicates\n",
    "    shift_rows = list(set(shift_rows))\n",
    "    # check that the selected segment starting point(s) exist\n",
    "    if not all([(e in src_alignment.index) for e in shift_rows]):\n",
    "        return False\n",
    "    if shift_col not in src_alignment.columns:\n",
    "        return False\n",
    "    # get the index numbers we are working with\n",
    "    colindex_start = list(src_alignment.columns).index(shift_col)\n",
    "    # check that the entire selected segment is contained within the alignment\n",
    "    if colindex_start + shift_size > len(src_alignment.columns):\n",
    "        return False\n",
    "    # check that the proposed shift is contained within the alignment\n",
    "    if (colindex_start + shift_distance) < 0 or (colindex_start + shift_distance) >= len(src_alignment.columns):\n",
    "        return False\n",
    "    if (colindex_start + (shift_size-1) + shift_distance) < 0 or (colindex_start + (shift_size-1) + shift_distance) >= len(src_alignment.columns):\n",
    "        return False\n",
    "    # check that the alignment segment(s) is entirely text and does not contain whitespace\n",
    "    if any([any([len(e[0].strip())==0 for e in src_alignment.loc[shift_row][colindex_start:colindex_start+shift_size]]) for shift_row in shift_rows]):\n",
    "        return False\n",
    "    # if the shift distance is 0, it always works (although it's a very useless shift)\n",
    "    if shift_distance==0:\n",
    "        return True\n",
    "    # figure out if the shift collides with any other text for each of the rows we want to shift\n",
    "    for shift_row in shift_rows:\n",
    "        if shift_distance > 0:\n",
    "            can_reach = [\n",
    "                i for i\n",
    "                in range(colindex_start+shift_size, min(len(src_alignment.loc[shift_row]), colindex_start+shift_size+shift_distance))\n",
    "            ]\n",
    "        elif shift_distance < 0:\n",
    "            can_reach = [\n",
    "                i for i \n",
    "                in reversed(range(max(0, colindex_start+shift_distance), colindex_start))\n",
    "            ]\n",
    "        can_reach = [(i, src_alignment.loc[shift_row][i][0].strip()=='') for i in can_reach]\n",
    "        # check whether we should continue with the shift\n",
    "        if not all([e[1] for e in can_reach]):\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "# canShiftCells(toy_align, [7321], 'txt1', 1, 3)\n",
    "# canShiftCells(toy_align, [7321], 'txt1', 2, 3)\n",
    "# canShiftCells(toy_align, [7321], 'txt1', 3, 3)\n",
    "# canShiftCells(toy_align, [7321], 'txt1', 4, 3)\n",
    "# canShiftCells(toy_align, [7321], 'txt1', 5, 3)\n",
    "# canShiftCells(toy_align, [7321], 'txt1', 6, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### shift cells\n",
    "[shiftCell documentation](https://github.com/cephcyn/alignpaper/blob/master/documentation/multiple_alignment.md#shiftCell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If it is impossible to shift the cells as specified, throws a ValueError\n",
    "def shiftCells(src_alignment, shift_rows, shift_col, shift_distance, shift_size=1, emptycell=('','',[]), debug_print=False):\n",
    "    if debug_print:\n",
    "        print(f'shift rows {shift_rows}, {shift_size} cells starting from {shift_col}, {shift_distance} cells over')\n",
    "    # check if it's possible to shift\n",
    "    if not canShiftCells(src_alignment, shift_rows, shift_col, shift_distance, shift_size):\n",
    "        raise ValueError('impossible to shift with given parameters: ' \n",
    "                         + f'(shift row {shift_rows}, {shift_size} cells starting from {shift_col}, {shift_distance} cells over)')\n",
    "    # initialize the alignment table copy we'll be working with\n",
    "    result = src_alignment.copy()\n",
    "    # get the index numbers we are working with\n",
    "    colindex_start = list(result.columns).index(shift_col)\n",
    "    for shift_row in shift_rows:\n",
    "        # grab the old contents\n",
    "        clipboard = [e for e in result.loc[shift_row][colindex_start:colindex_start+shift_size]]\n",
    "        # replace old contents with empty tuples\n",
    "        for i in range(colindex_start, colindex_start+shift_size):\n",
    "            result.loc[shift_row][i] = emptycell\n",
    "        # put old content in its destination location\n",
    "        for i in range(len(clipboard)):\n",
    "            result.loc[shift_row][colindex_start+shift_distance+i] = clipboard[i]\n",
    "    return result # removeEmptyColumns(result)\n",
    "\n",
    "# shiftCells(toy_align, [7321], 'txt1', 1, shift_size=3)\n",
    "# shiftCells(toy_align, [7298], 'txt2', -1, shift_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for i in [7298, 7321, 5126, 5134, 4594, 4618, 6507, 6474, 7308, 5130, 2552]:\n",
    "#     alignment_df.loc[[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Alignment in manually selected \"nice\" order without types enforced\n",
    "# temp_align = []\n",
    "# temp_align.append(alignRowMajorLocal(alignment_df.loc[[5126]], alignment_df.loc[[5134]], \n",
    "#                                      remove_empty_cols=True)[0])\n",
    "# temp_align.append(alignRowMajorLocal(alignment_df.loc[[7298]], alignment_df.loc[[7321]], \n",
    "#                                      remove_empty_cols=True)[0])\n",
    "# temp_align.append(alignRowMajorLocal(alignment_df.loc[[4594]], alignment_df.loc[[4618]], \n",
    "#                                      remove_empty_cols=True)[0])\n",
    "# temp_align.append(alignRowMajorLocal(alignment_df.loc[[5130]], alignment_df.loc[[2552]], \n",
    "#                                      remove_empty_cols=True)[0])\n",
    "# temp_align.append(alignRowMajorLocal(alignment_df.loc[[6474]], alignment_df.loc[[7308]], \n",
    "#                                      remove_empty_cols=True)[0])\n",
    "# update_temp_align = []\n",
    "# update_temp_align.append(alignRowMajorLocal(temp_align[2], temp_align[3])[0])\n",
    "# update_temp_align.append(alignRowMajorLocal(temp_align[1], temp_align[4])[0])\n",
    "# update_temp_align.append(alignRowMajorLocal(temp_align[0], alignment_df.loc[[6507]], \n",
    "#                                             remove_empty_cols=True)[0])\n",
    "# temp_align = update_temp_align\n",
    "# update_temp_align = []\n",
    "# update_temp_align.append(alignRowMajorLocal(temp_align[0], temp_align[2])[0])\n",
    "# manually_aligned_group, manually_aligned_group_score = alignRowMajorLocal(update_temp_align[0], temp_align[1])\n",
    "# print(manually_aligned_group_score)\n",
    "# extractTup(manually_aligned_group, tup_i='segment').sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Demonstrate a merge operation\n",
    "# manually_aligned_group_merge = mergeCol(manually_aligned_group, 'txt4')\n",
    "# manually_aligned_group_merge = mergeCol(manually_aligned_group_merge, 'txt4')\n",
    "# manually_aligned_group_merge = mergeCol(manually_aligned_group_merge, 'txt1')\n",
    "# manually_aligned_group_merge = mergeCol(manually_aligned_group_merge, 'txt4')\n",
    "# manually_aligned_group_merge.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Demonstrate a split operation\n",
    "# manually_aligned_group_split = splitCol(manually_aligned_group_merge, 'txt0', right_align=True)\n",
    "# manually_aligned_group_split = splitCol(manually_aligned_group_split, 'txt4', right_align=False)\n",
    "# manually_aligned_group_split = splitCol(manually_aligned_group_split, 'txt5', right_align=True)\n",
    "# manually_aligned_group_split = splitCol(manually_aligned_group_split, 'txt7', right_align=False)\n",
    "# manually_aligned_group_split.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #          [5130, 5126, 5134, 4618, 6507, 4594, 7321, 7298, 2552, 6474, 7308] # experiment 1, topic \"autism\"\n",
    "# #          [2380, 2711, 2437, 6915, 4887, 2078, 2030, 2849, 3194, 3285, 5437] # experiment 2, topic \"cancer\"\n",
    "# #          [1248, 1275, 1381, 1387, 3871, 4039, 5202, 5204, 6563, 6569]       # experiment 3, topic \"diabetes\", untuned order\n",
    "# id_order = [1248, 1275, 1381, 1387, 3871, 4039, 5202, 5204, 6563, 6569]\n",
    "\n",
    "# alignment_wordsonly, alignment_score = alignRowMajorLocal(\n",
    "#     alignment_df_tseg.loc[[id_order[0]]],\n",
    "#     alignment_df_tseg.loc[[id_order[1]]],\n",
    "#     remove_empty_cols=True, \n",
    "#     use_types=True\n",
    "# )\n",
    "# for i in range(2, len(id_order)):\n",
    "#     alignment_wordsonly, alignment_score = alignRowMajorLocal(\n",
    "#         alignment_wordsonly,\n",
    "#         alignment_df_tseg.loc[[id_order[i]]],\n",
    "#         remove_empty_cols=True, \n",
    "#         use_types=True\n",
    "#     )\n",
    "# extractTup(alignment_wordsonly, tup_i='segment').sort_index()\n",
    "# alignment_wordsonly.sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse alignment DF into copy-pastable spreadsheet format\n",
    "(This relies on the pandas dataframe preview embed in Jupyter Notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note that this will output double quotes in POS rows oddly - need to manually merge them back due to a quirk in how pandas formats data\n",
    "# TODO have this export directly to file if possible?\n",
    "def spreadsheetFormat(alignment_df):\n",
    "    alignment_df = alignment_df.sort_index()\n",
    "    alignment_pos = extractTup(alignment_df, tup_i='cpos') # the token part of speech\n",
    "    alignment_segment = extractTup(alignment_df, tup_i='segment')\n",
    "    alignment_ppos = extractTup(alignment_df, tup_i='pos') # the phrase part of speech\n",
    "    output_columns = ['id', 'fulltext', 'datatype', 'empty']+[str(i) for i in range(len(alignment_df.columns))]\n",
    "    output_data = []\n",
    "    row_length = len(output_columns)\n",
    "    for i in alignment_df.index:\n",
    "        fulltext = ' '.join([e for e in alignment_segment.loc[i].tolist() if len(e.strip())>0])\n",
    "#         ppos = [i, fulltext, 's-ppos', '']+[e for e in alignment_ppos.loc[i].tolist() if len(e.strip())>0]\n",
    "#         ppos = ppos + ['']*(len(output_columns)-len(ppos))\n",
    "#         output_data.append(ppos)\n",
    "        pos = [i, fulltext, 's-pos', '']+[([f'\\'{i}\\'' for i in e] if len(e)>0 else '') for e in alignment_pos.loc[i].tolist()]\n",
    "        pos = pos + ['']*(len(output_columns)-len(pos))\n",
    "        output_data.append(pos)\n",
    "        txt = [i, fulltext, 's-txt', '']+alignment_segment.loc[i].tolist()\n",
    "        txt = txt + ['']*(len(output_columns)-len(txt))\n",
    "        output_data.append(txt)\n",
    "    output_df = pd.DataFrame(\n",
    "        output_data, \n",
    "        columns=output_columns)\n",
    "    return output_df\n",
    "\n",
    "# spreadsheetFormat(alignment_wordsonly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alignment scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os.path\n",
    "import pickle\n",
    "\n",
    "if not os.path.isfile('temp/align_temp_qualitycompare.pkl'):\n",
    "    # create some reference alignments\n",
    "    reference_alignment = []\n",
    "    reference_alignment_orderings = []\n",
    "    reference_alignment_scores = []\n",
    "    temp_ids_list = [\n",
    "    #     [5130, 5126, 6507, 6474, 7308, 5134, 2552, 4618, 7298, 4594, 7321], # decent\n",
    "        [7321, 5134, 4594, 6507, 2552, 5130, 7298, 7308, 4618, 6474, 5126], # decent\n",
    "    #     [5134, 7298, 4618, 6507, 7321, 5126, 6474, 5130, 4594, 2552, 7308], # bad\n",
    "    #     [5126, 5134, 4618, 7298, 6507, 5130, 6474, 4594, 7308, 2552, 7321], # quite bad (chaotic)\n",
    "        [5126, 7321, 7298, 5130, 6474, 4618, 4594, 7308, 2552, 6507, 5134]  # quite bad (sharply split)\n",
    "    ]\n",
    "    for i in range(len(temp_ids_list)):\n",
    "        temp_ids = temp_ids_list[i]\n",
    "        alignment, alignment_score = alignRowMajorLocal(\n",
    "            alignment_df.loc[[temp_ids[0]]], \n",
    "            alignment_df.loc[[temp_ids[1]]], \n",
    "            remove_empty_cols=True\n",
    "        )\n",
    "        temp_scores = [0, alignment_score]\n",
    "        for j in range(2, len(temp_ids)):\n",
    "            alignment, alignment_score = alignRowMajorLocal(\n",
    "                alignment,\n",
    "                alignment_df.loc[[temp_ids[j]]], \n",
    "                remove_empty_cols=True\n",
    "            )\n",
    "            temp_scores.append(alignment_score)\n",
    "        reference_alignment.append(alignment)\n",
    "        reference_alignment_orderings.append(temp_ids)\n",
    "        reference_alignment_scores.append(temp_scores)\n",
    "    # dump to a file\n",
    "    pickle.dump(\n",
    "        (reference_alignment,reference_alignment_orderings,reference_alignment_scores), \n",
    "        open(f'temp/align_temp_qualitycompare.pkl', 'wb')\n",
    "    )\n",
    "# retrieve the alignments from file\n",
    "temp = pickle.load(open(f'temp/align_temp_qualitycompare.pkl', 'rb'))\n",
    "reference_alignment,reference_alignment_orderings,reference_alignment_scores = temp\n",
    "\n",
    "# Here's an alignment that's pretty bad:\n",
    "toy_alignment_poor = reference_alignment[1]\n",
    "extractTup(toy_alignment_poor, tup_i='segment').sort_index()\n",
    "# Here's an alignment that's okay:\n",
    "toy_alignment_good = reference_alignment[0]\n",
    "extractTup(toy_alignment_good, tup_i='segment').sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### total col count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scoreNumColumns(align_df):\n",
    "    return len(align_df.columns)\n",
    "\n",
    "# # Lower is better\n",
    "# print(' poor', scoreNumColumns(toy_alignment_poor))\n",
    "# print(' good', scoreNumColumns(toy_alignment_good))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### content col count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scoreNumFilledColumns(align_df):\n",
    "    # empty columns don't count, so discount those...\n",
    "    contents = [align_df[colname] for colname in align_df.columns]\n",
    "    contents = [len([cell[0] for cell in t if cell[0].strip()!='']) for t in contents]\n",
    "    contents = [(1 if t>0 else 0) for t in contents]\n",
    "    return sum(contents)\n",
    "\n",
    "# # Lower is better\n",
    "# print(' poor', scoreNumFilledColumns(toy_alignment_poor))\n",
    "# print(' good', scoreNumFilledColumns(toy_alignment_good))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### col embed variation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def scoreColumnPhraseEmbedVariance(align_df, colname, embed_model):\n",
    "    # Compute embeddings variance of all the phrases for a single column\n",
    "    texts = [text for text in extractTup(align_df[colname], tup_i='segment', is_frame=False)]\n",
    "    # take the set of row texts\n",
    "    texts = list(set(texts))\n",
    "    # build up the list of text embeds for the texts that we *can* compute an embed for\n",
    "    text_embeds = []\n",
    "    for word in texts:\n",
    "        try:\n",
    "            text_embeds.append(get_phrase_embed(embed_model, word).drop('word', 1))\n",
    "        except:\n",
    "            pass\n",
    "    if len(text_embeds) > 1:\n",
    "        output = pd.concat(text_embeds)\n",
    "        # Reasoning for this operation (calculating variance as trace(covariance matrix) ...):\n",
    "        # https://stats.stackexchange.com/questions/225434/a-measure-of-variance-from-the-covariance-matrix\n",
    "        # This is equivalent to calculating the expected Euclidean distance of each element from the mean\n",
    "        result = np.trace(output.cov())\n",
    "    else:\n",
    "        # one of two scenarios:\n",
    "        # 1. all of the contents of this column aren't considered words, so, pretend they're all the same\n",
    "        # 2. there is only one row in this column that contains text, so it has no variation\n",
    "        # TODO is there a theoretically better way to handle them?\n",
    "        result = 0\n",
    "    return result\n",
    "\n",
    "# # Lower is better\n",
    "# print(' poor', scoreColumnPhraseEmbedVariance(toy_alignment_poor, 'txt0', word2vec))\n",
    "# print(' good', scoreColumnPhraseEmbedVariance(toy_alignment_good, 'txt0', word2vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scoreColumnTextCount(align_df, colname):\n",
    "    # Count the number of unique texts in a single column\n",
    "    # capture each cell text\n",
    "    tokens = [text for text in extractTup(align_df[colname], tup_i='segment', is_frame=False)\n",
    "              if text.strip() != '']\n",
    "    # clean up whitespace\n",
    "    tokens = [text.split() for text in tokens]\n",
    "    # flatten\n",
    "    tokens = [' '.join(sublist) for sublist in tokens]\n",
    "    return len(set(tokens))\n",
    "\n",
    "# # Lower is better\n",
    "# print(' poor', scoreColumnTextCount(toy_alignment_poor, 'txt0'))\n",
    "# print(' good', scoreColumnTextCount(toy_alignment_good, 'txt0'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def variationCount(tokens):\n",
    "    # remove empty rows entirely\n",
    "    tokens = [e for e in tokens if len(e)!=0]\n",
    "    numrows = len(tokens)\n",
    "    # get the set-list\n",
    "    tokenset = list(set([e for sl in tokens for e in sl]))\n",
    "    # get the count of how many rows each token appears in\n",
    "    tokencount = dict([(e, len([1 for sl in tokens if e in sl])) for e in tokenset])\n",
    "    # remove the ones that are present in every row\n",
    "    return len([e for e in tokencount if tokencount[e]!=numrows])\n",
    "\n",
    "variationCount(\n",
    "    [\n",
    "        ['children'], \n",
    "        ['Fifty', 'children'], \n",
    "        ['children'], \n",
    "        ['45', 'children'], \n",
    "#         ['patients'], \n",
    "#         ['573', 'patients'], \n",
    "#         ['primary', 'care', 'patients'], \n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### col token count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scoreColumnTokenCount(align_df, colname):\n",
    "    # TODO normalize this\n",
    "    # Count the number of unique tokens in a single column\n",
    "    # capture each cell text\n",
    "    tokens = [\n",
    "        text for text in extractTup(align_df[colname], tup_i='segment', is_frame=False)\n",
    "        if text.strip() != ''\n",
    "    ]\n",
    "    # split it into tokens\n",
    "    tokens = [text.split() for text in tokens]\n",
    "    # flatten\n",
    "    return len(set([token for sublist in tokens for token in sublist]))\n",
    "#     # the implementation for variation count...\n",
    "#     # Count the number of unique tokens in a single column that AREN'T IN ALL OF THE ROWS\n",
    "#     # capture each cell text\n",
    "#     tokens = [text for text in extractTup(align_df[colname], tup_i='segment', is_frame=False)\n",
    "#               if text.strip() != '']\n",
    "#     # split it into tokens\n",
    "#     tokens = [text.split() for text in tokens]\n",
    "#     return variationCount(tokens)\n",
    "\n",
    "# # Lower is better\n",
    "# print(' poor', scoreColumnTokenCount(toy_alignment_poor, 'txt0'))\n",
    "# print(' good', scoreColumnTokenCount(toy_alignment_good, 'txt0'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scoreColumnTokenEntityCount(align_df, colname, scisp, scisp_linker):\n",
    "    # input argument scisp: scispacy model (default should be scisp = spacy.load('en_core_sci_sm'))\n",
    "    # input argument scisp_linker: scispacy model linker\n",
    "    # Count the number of unique entity types in a single column\n",
    "    types = [text for text in extractTup(align_df[colname], tup_i='segment', is_frame=False)\n",
    "             if text.strip() != '']\n",
    "    # process the texts through spacy and pick out entities\n",
    "    types = [scisp(text).ents for text in types]\n",
    "    # flatten the entities and put into a set\n",
    "    types = [[ent for ent in ents] for ents in types]\n",
    "    # get the UMLS mappings for each entity\n",
    "    types = [[ent._.umls_ents[0][0] for ent in sl if (len(ent)>0) and (len(ent._.umls_ents)>0)] for sl in types]\n",
    "    # get the TUI for each of these UMLS mappings\n",
    "    # An informal guide to all of the TUIs: https://gist.github.com/joelkuiper/4869d148333f279c2b2e\n",
    "    types_tui = [[scisp_linker.umls.cui_to_entity[ent].types for ent in sl] for sl in types]\n",
    "    # check for edge case where there's 0 UMLS tuis for something?\n",
    "    for sl in types_tui:\n",
    "        if any([len(e)<1 for e in sl]):\n",
    "            raise ValueError('<1 tui for a UMLS entity')\n",
    "    types_tui = [[e for sl in row for e in sl] for row in types_tui]\n",
    "    # TODO implement larger groupings of types / more general type groups...\n",
    "    # https://semanticnetwork.nlm.nih.gov/download/SemGroups.txt\n",
    "    # from https://semanticnetwork.nlm.nih.gov/\n",
    "    return len(set([e for sl in types for e in sl])), len(set([e for sl in types_tui for e in sl]))\n",
    "\n",
    "# # Lower is better\n",
    "# print(' poor', scoreColumnTokenEntityCount(toy_alignment_poor, 'txt0', scisp=scisp, scisp_linker=linker))\n",
    "# print(' good', scoreColumnTokenEntityCount(toy_alignment_good, 'txt0', scisp=scisp, scisp_linker=linker))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### col token entity variation count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scoreColumnTokenEntityVariationCount(align_df, colname):\n",
    "    # Count the number of unique entity types in a single column\n",
    "    # while accounting for varying entity frequencies across rows\n",
    "    types = [text for text in extractTup(align_df[colname], tup_i='segment', is_frame=False)\n",
    "             if text.strip() != '']\n",
    "    # process the texts through spacy and pick out entities\n",
    "    types = [scisp(text).ents for text in types]\n",
    "    # flatten the entities and put into a set\n",
    "    types = [[ent for ent in ents] for ents in types]\n",
    "    # get the UMLS mappings for each entity\n",
    "    types = [[ent._.umls_ents[0][0] for ent in sl if (len(ent)>0) and (len(ent._.umls_ents)>0)] for sl in types]\n",
    "    # get the TUI for each of these UMLS mappings\n",
    "    # An informal guide to all of the TUIs: https://gist.github.com/joelkuiper/4869d148333f279c2b2e\n",
    "    types_tui = [[linker.umls.cui_to_entity[ent].types for ent in sl] for sl in types]\n",
    "    # check for edge case where there's 0 UMLS tuis for something?\n",
    "    for sl in types_tui:\n",
    "        if any([len(e)<1 for e in sl]):\n",
    "            raise ValueError('<1 tui for a UMLS entity')\n",
    "    types_tui = [[e for sl in row for e in sl] for row in types_tui]\n",
    "    # TODO implement larger groupings of types / more general type groups...\n",
    "    # https://semanticnetwork.nlm.nih.gov/download/SemGroups.txt\n",
    "    # from https://semanticnetwork.nlm.nih.gov/\n",
    "    return variationCount(types), variationCount(types_tui)\n",
    "\n",
    "# # # Lower is better\n",
    "# print(' poor', scoreColumnTokenEntityVariationCount(toy_alignment_poor, 'txt0'))\n",
    "# print(' good', scoreColumnTokenEntityVariationCount(toy_alignment_good, 'txt0'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scoreColumnPhrasePOSCount(align_df, colname):\n",
    "    # Count the number of unique phrase parts-of-speech in a single column\n",
    "    tokens = [phrasepos for phrasepos in extractTup(align_df[colname], tup_i='pos', is_frame=False)\n",
    "              if phrasepos.strip() != '']\n",
    "    return len(set(tokens))\n",
    "\n",
    "# # Lower is better\n",
    "# print(' poor', scoreColumnPhrasePOSCount(toy_alignment_poor, 'txt0'))\n",
    "# print(' good', scoreColumnPhrasePOSCount(toy_alignment_good, 'txt0'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scoreColumnPOSCount(align_df, colname):\n",
    "    # Count the number of unique token parts-of-speech in a single column\n",
    "    tokens = [pos_list for pos_list in extractTup(align_df[colname], tup_i='cpos', is_frame=False)]\n",
    "    return len(set([pos for pos_list in tokens for pos in pos_list if pos.strip() != '']))\n",
    "\n",
    "# # Lower is better\n",
    "# print(' poor', scoreColumnPOSCount(toy_alignment_poor, 'txt0'))\n",
    "# print(' good', scoreColumnPOSCount(toy_alignment_good, 'txt0'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scoreColumnPOSVariationCount(align_df, colname):\n",
    "    # Count the number of unique token parts-of-speech in a single column\n",
    "    # while accounting for varying token POS frequencies across rows\n",
    "    tokens = [pos_list for pos_list in extractTup(align_df[colname], tup_i='cpos', is_frame=False)]\n",
    "    return variationCount(tokens)\n",
    "\n",
    "# # Lower is better\n",
    "# print(' poor', scoreColumnPOSVariationCount(toy_alignment_poor, 'txt0'))\n",
    "# print(' good', scoreColumnPOSVariationCount(toy_alignment_good, 'txt0'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scoreColumnRepresentation(align_df, colname):\n",
    "    # Count the fraction of rows that are represented in the column (so penalizes gaps)\n",
    "    tokens = [text for text in extractTup(align_df[colname], tup_i='segment', is_frame=False)]\n",
    "    non_empty_count = len([text for text in tokens if text.strip() != ''])\n",
    "    return non_empty_count/len(tokens)\n",
    "\n",
    "# # Higher is better\n",
    "# print(' poor', scoreColumnRepresentation(toy_alignment_poor, 'txt0'))\n",
    "# print(' good', scoreColumnRepresentation(toy_alignment_good, 'txt0'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scoreColumnTotalTokens(align_df, colname):\n",
    "    # Count the number of words (including repeats) in each column\n",
    "    tokens = [text.split(' ') for text in extractTup(align_df[colname], tup_i='segment', is_frame=False)]\n",
    "    tokens = [e for sublist in tokens for e in sublist if e!='']\n",
    "    return len(tokens)\n",
    "\n",
    "# # Higher is better\n",
    "# print(' poor', scoreColumnTotalTokens(toy_alignment_poor, 'txt0'))\n",
    "# print(' good', scoreColumnTotalTokens(toy_alignment_good, 'txt0'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scoreRowAlignment(align_df, focus_row):\n",
    "    # Calculate the alignment score that a specific row would get if aligned with the df\n",
    "    # Score is normalized by the number of operations that goes into calculating it\n",
    "    # (there is a score matrix that is len(mat_a)*len(mat_b) dimensions)\n",
    "    # TODO there should be a way to re-derive this based on the direct alignment?\n",
    "    score = alignRowMajorLocal(align_df, focus_row, remove_empty_cols=True)[1]\n",
    "    return score / (len(align_df.columns) + len(focus_row.columns))\n",
    "\n",
    "# # Higher is better\n",
    "# print(' poor', scoreRowAlignment(toy_alignment_poor, toy_alignment_poor.loc[[5130]]))\n",
    "# print(' good', scoreRowAlignment(toy_alignment_good, toy_alignment_good.loc[[5130]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### term column count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scoreTermColumnCount(align_df, term):\n",
    "    # Count the number of columns that a certain phrase or term appears within\n",
    "    # TODO should this be a fraction instead? what would that imply?\n",
    "    # If it doesn't appear at all, returns 1 (TODO that might not be ideal?)\n",
    "    # TODO add support for regex patterns (eg numbers?)\n",
    "    tokens = [\n",
    "        [text for text in extractTup(align_df[colname], tup_i='segment', is_frame=False)]\n",
    "        for colname in align_df.columns\n",
    "    ]\n",
    "    tokens = [[e for e in col if (term.lower() in e.lower())] for col in tokens]\n",
    "    tokens = [col for col in tokens if len(col) != 0]\n",
    "    return max(1, len(tokens))\n",
    "\n",
    "def scoreTermListColumnCount(align_df, term_list, term_weights=None):\n",
    "    # if we don't have any terms to investigate, return 1 (default col count)\n",
    "    if len(term_list) == 0:\n",
    "        return 1\n",
    "    # by default, weight each term equally\n",
    "    if term_weights is None:\n",
    "        term_weights = [1]*len(term_list)\n",
    "    # And normalize the weights (assume that hasn't been done already)\n",
    "    tw_sum = sum(term_weights)\n",
    "    term_weights = [(tw/tw_sum) for tw in term_weights]\n",
    "    scores = [scoreTermColumnCount(align_df, term) for term in term_list]\n",
    "    return np.dot(scores, term_weights)\n",
    "\n",
    "# # Lower is better\n",
    "# print(' poor', scoreTermColumnCount(toy_alignment_poor, 'anxiety'))\n",
    "# print(' good', scoreTermColumnCount(toy_alignment_good, 'anxiety'))\n",
    "# print()\n",
    "\n",
    "# # Test of using scoreTermListColumnCount with multiple terms (weighted equally)\n",
    "# # Lower is better\n",
    "# temp_list = ['anxiety', 'patient', 'children', 'child']\n",
    "# scores = scoreTermListColumnCount(toy_alignment_poor, temp_list)\n",
    "# print('poor', scores)\n",
    "# scores = scoreTermListColumnCount(toy_alignment_good, temp_list)\n",
    "# print('good', scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scoreRowLayoutCount(align_df):\n",
    "    # Count the number of unique content-gap orderings that are present in the alignment\n",
    "    rows = [\n",
    "        list(extractTup(align_df.iloc[i], tup_i='segment', is_frame=False)) \n",
    "        for i in range(len(align_df))]\n",
    "    rows = [''.join([('.' if (e.strip() != '') else ' ') for e in r]) for r in rows]\n",
    "    return len(set(rows))\n",
    "\n",
    "# # Lower is better\n",
    "# print(' poor', scoreRowLayoutCount(toy_alignment_poor))\n",
    "# print(' good', scoreRowLayoutCount(toy_alignment_good))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alignmentTermWeights(align_df, sp, all_stopwords=None, priority_pos=['NN', 'NNS', 'NNP', 'JJ', 'RB']):\n",
    "    # input argument sp: spacy model (default should be sp = spacy.load('en_core_web_sm'))\n",
    "    if all_stopwords is None:\n",
    "        all_stopwords = sp.Defaults.stop_words\n",
    "    # collect list forms of words and cPOS\n",
    "    all_text = [\n",
    "        [text for text in extractTup(align_df.iloc[rownum], tup_i='segment', is_frame=False)]\n",
    "        for rownum in range(len(align_df))\n",
    "    ]\n",
    "    all_text = [' '.join(sublist).split() for sublist in all_text]\n",
    "    all_cpos = [\n",
    "        [text for sublist\n",
    "         in extractTup(align_df.iloc[rownum], tup_i='cpos', is_frame=False)\n",
    "         for text in sublist]\n",
    "        for rownum in range(len(align_df))\n",
    "    ]\n",
    "    # get count of how many rows each word is present in\n",
    "    tokens_df = dict([\n",
    "        (word, sum([(word in row) for row in all_text]))\n",
    "        for word\n",
    "        in set([item for sublist in all_text for item in sublist])\n",
    "        if word not in all_stopwords\n",
    "    ])\n",
    "    # remove the words that show up in at most one row\n",
    "    for word in [word for word in tokens_df if tokens_df[word] <= 1]:\n",
    "        discard = tokens_df.pop(word, None)\n",
    "    # flatten the word and cPOS lists\n",
    "    all_text = [e for sublist in all_text for e in sublist]\n",
    "    all_cpos = [e for sublist in all_cpos for e in sublist if e != '']\n",
    "    # count up how many POS is assigned to each word\n",
    "    pos_mapping = {}\n",
    "    for i in range(len(all_text)):\n",
    "        if all_text[i] not in pos_mapping:\n",
    "            pos_mapping[all_text[i]] = {}\n",
    "        if all_cpos[i] not in pos_mapping[all_text[i]]:\n",
    "            pos_mapping[all_text[i]][all_cpos[i]] = 0\n",
    "        pos_mapping[all_text[i]][all_cpos[i]] += 1\n",
    "    # pick the single POS that each word is tagged as most often\n",
    "    for word in pos_mapping:\n",
    "        max_pos = None\n",
    "        max_count = 0\n",
    "        for pos in pos_mapping[word]:\n",
    "            if pos_mapping[word][pos] > max_count:\n",
    "                max_pos = pos\n",
    "                max_count = pos_mapping[word][pos]\n",
    "        pos_mapping[word] = max_pos\n",
    "    # exponentiate the count of all of the words in the dict that are in POS classes we care about\n",
    "    for word in tokens_df:\n",
    "        if any([(pos in pos_mapping[word]) for pos in priority_pos]):\n",
    "            tokens_df[word] = pow(tokens_df[word], 2)\n",
    "    return tokens_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test how much sense this weighting works for scoreTermListColumnCount\n",
    "# tokens_df = alignmentTermWeights(toy_alignment_bad, sp=sp)\n",
    "# temp_list = list(tokens_df)\n",
    "# temp_weights = list(tokens_df.values())\n",
    "# scores = scoreTermListColumnCount(toy_alignment_poor, temp_list, term_weights=temp_weights)\n",
    "# print('poor', scores)\n",
    "# scores = scoreTermListColumnCount(toy_alignment_good, temp_list, term_weights=temp_weights)\n",
    "# print('good', scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### alignment score function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import traceback\n",
    "\n",
    "# TODO how do we design this score function that it may be comparable with other alignments?\n",
    "def scoreAlignment(align_df, spacy_model, scispacy_model, scispacy_linker, embed_model, max_row_length=None, term_weight_func=None, weight_components=None):\n",
    "    # set default score weights...\n",
    "    if weight_components is None:\n",
    "        weight_components = np.array([0.2, 0.2, 1, 0, 0, 0])\n",
    "\n",
    "    # ideally, only calculate the max row length once for each optimization search, but we can do that per-alignment if it's not provided\n",
    "    if max_row_length is None:\n",
    "        print('scoreAlignment: prefer having max_row_length input')\n",
    "        traceback.print_stack(limit=5)\n",
    "        max_row_length = max([len([e[0] for e in align_df.loc[i] if len(e[0])!=0]) for i in align_df.index])\n",
    "\n",
    "    # get term weights\n",
    "    if term_weight_func is None:\n",
    "        alignment_terms = alignmentTermWeights(align_df, sp=spacy_model)\n",
    "        term_list = list(alignment_terms)\n",
    "        weight_terms = list(alignment_terms.values())\n",
    "    weight_terms = [r/sum(weight_terms) for r in weight_terms] # normalize the weights\n",
    "\n",
    "    # get column weights\n",
    "    score_colalltokens = [scoreColumnRepresentation(align_df, colname) for colname in align_df.columns]\n",
    "#     score_colalltokens = [scoreColumnTotalTokens(align_df, colname) for colname in align_df.columns]\n",
    "#     score_colalltokens = [1 for colname in align_df.columns]\n",
    "    weight_columns = [r/sum(score_colalltokens) for r in score_colalltokens] # normalize the column weights\n",
    "\n",
    "    # get score components\n",
    "    score_numcolumns = scoreNumColumns(align_df)\n",
    "    score_numfilledcolumns = scoreNumFilledColumns(align_df)\n",
    "    score_colptxtembed = [scoreColumnPhraseEmbedVariance(align_df, colname, embed_model) for colname in align_df.columns]\n",
    "    score_coltokncount = [scoreColumnTokenCount(align_df, colname) for colname in align_df.columns]\n",
    "    raw_colentityscores = [\n",
    "        scoreColumnTokenEntityCount(align_df, colname, scisp=scispacy_model, scisp_linker=scispacy_linker) \n",
    "        for colname in align_df.columns\n",
    "    ]\n",
    "#     raw_colentityscores = [(0,0) for colname in align_df.columns] # cheap filler score - use if scispacy not imported properly\n",
    "    score_coltentcount = [s[0] for s in raw_colentityscores]\n",
    "    score_colttuicount = [s[1] for s in raw_colentityscores]\n",
    "    score_termcolcount = scoreTermListColumnCount(align_df, term_list, weight_terms)\n",
    "\n",
    "    # put score components into a df of their own that is neatly readable for debug purposes\n",
    "    rawscores = pd.DataFrame([\n",
    "        # text embed vector variance; lower is better\n",
    "        score_colptxtembed,\n",
    "        # distinct tokens; lower is better\n",
    "        score_coltokncount,\n",
    "        # varying distinct entity TUIs; lower is better\n",
    "        score_colttuicount,\n",
    "        # the weighting we are giving each column; higher means more attention\n",
    "        weight_columns,\n",
    "    ], index=[\n",
    "        'embed variance',\n",
    "        'unique tokens (var)',\n",
    "        'unique entity TUI (var)',\n",
    "        'relevance (numtokens)',\n",
    "    ])\n",
    "    rawscores = rawscores.rename(columns=dict(zip(rawscores.columns, align_df.columns)))\n",
    "\n",
    "    # apply column weights to the score components\n",
    "    components = np.array([\n",
    "        # number of columns; lower is better\n",
    "        -1 * math.pow((score_numcolumns / max_row_length), 1),\n",
    "        # number of filled columns; lower is better\n",
    "        -1 * math.pow((score_numfilledcolumns / max_row_length), 1),\n",
    "        # text embed vector variance; lower is better\n",
    "        -1 * np.dot([math.pow(s, 2) for s in score_colptxtembed], weight_columns),\n",
    "        # varying distinct tokens; lower is better\n",
    "        -1 * np.dot(score_coltokncount, weight_columns),\n",
    "        # varying distinct entity TUIs; lower is better\n",
    "        -1 * np.dot(score_colttuicount, weight_columns),\n",
    "        # column count of terms used; lower is better\n",
    "        -1 * score_termcolcount,\n",
    "    ])\n",
    "    # apply score component weights (higher total score is better)\n",
    "    bias = 5\n",
    "    singlescore = bias + np.dot(weight_components, components)\n",
    "    return singlescore, components, rawscores\n",
    "\n",
    "# singlescore, components, rawscores = scoreAlignment(toy_alignment_poor, spacy_model=sp, scispacy_model=scisp, scispacy_linker=linker, embed_model=fasttext, max_row_length=13)\n",
    "# singlescore\n",
    "# components\n",
    "# rawscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import random\n",
    "\n",
    "# # TODO remove?\n",
    "# # Experiment to see how much random ordering impacts alignment readability\n",
    "# temp_ids = [2552, 4594, 4618, 5130, 6474, 7298, 7308, 7321, 5126, 5134, 6507] # experiment 1\n",
    "# # temp_ids = [2030, 2078, 2380, 2437, 2711, 2849, 3194, 3285, 4887, 5437, 6915] # experiment 2\n",
    "# # temp_ids = [1248, 1275, 1381, 1387, 3871, 4039, 5202, 5204, 6563, 6569] # experiment 3\n",
    "# temp_alignment_orderings = []\n",
    "# temp_alignment_outputs = []\n",
    "# temp_alignment_score_progressions = []\n",
    "# for i in range(20):\n",
    "#     temp_ids = random.sample(temp_ids, len(temp_ids))\n",
    "#     alignment, alignment_score = alignRowMajorLocal(\n",
    "#         alignment_df.loc[[temp_ids[0]]], \n",
    "#         alignment_df.loc[[temp_ids[1]]], \n",
    "#         remove_empty_cols=True\n",
    "#     )\n",
    "#     temp_alignment_orderings.append(temp_ids)\n",
    "#     temp_alignment_outputs.append(alignment)\n",
    "#     temp_alignment_score_progressions.append([alignment_score])\n",
    "#     for j in range(2, len(temp_ids)):\n",
    "#         alignment, alignment_score = alignRowMajorLocal(\n",
    "#             temp_alignment_outputs[i],\n",
    "#             alignment_df.loc[[temp_ids[j]]], \n",
    "#             remove_empty_cols=True\n",
    "#         )\n",
    "#         temp_alignment_outputs[i] = alignment\n",
    "#         temp_alignment_score_progressions[i].append(alignment_score)\n",
    "# # extractTup(update_manually_aligned_group_realign, tup_i='segment').sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scoring function evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tempScoreVectorDetail(align_df):\n",
    "    # get term weights\n",
    "    alignment_terms = alignmentTermWeights(align_df, sp=sp)\n",
    "    term_list = list(alignment_terms)\n",
    "    term_weights = list(alignment_terms.values())\n",
    "    # TODO make this an actual nice function later\n",
    "    score_colptxtembed = [scoreColumnPhraseEmbedVariance(align_df, colname, word2vec) for colname in align_df.columns]\n",
    "    score_coltextcount = [scoreColumnTextCount(align_df, colname) for colname in align_df.columns]\n",
    "    score_coltokncount = [scoreColumnTokenCount(align_df, colname) for colname in align_df.columns]\n",
    "    raw_colentityscores = [scoreColumnTokenEntityCount(align_df, colname) for colname in align_df.columns]\n",
    "    score_coltentcount = [s[0] for s in raw_colentityscores]\n",
    "    score_colttuicount = [s[1] for s in raw_colentityscores]\n",
    "    raw_colentityvarscores = [scoreColumnTokenEntityVariationCount(align_df, colname) for colname in align_df.columns]\n",
    "    score_coltentvarcount = [s[0] for s in raw_colentityvarscores]\n",
    "    score_colttuivarcount = [s[1] for s in raw_colentityvarscores]\n",
    "    score_colpposcount = [scoreColumnPhrasePOSCount(align_df, colname) for colname in align_df.columns]\n",
    "    score_coltposcount = [scoreColumnPOSCount(align_df, colname) for colname in align_df.columns]\n",
    "    score_coltposvarcount = [scoreColumnPOSVariationCount(align_df, colname) for colname in align_df.columns]\n",
    "    score_colrepresent = [scoreColumnRepresentation(align_df, colname) for colname in align_df.columns]\n",
    "    score_colalltokens = [scoreColumnTotalTokens(align_df, colname) for colname in align_df.columns]\n",
    "    score_termcolcount = scoreTermListColumnCount(align_df, term_list, term_weights)\n",
    "    scores = np.array([\n",
    "        scoreNumColumns(align_df), # lower is better\n",
    "        sum(score_coltextcount)/len(score_coltextcount), # lower is better\n",
    "        sum(score_colptxtembed)/len(score_colptxtembed), # lower is better\n",
    "        sum(score_coltokncount)/len(score_coltokncount), # lower is better\n",
    "        sum(score_coltentcount)/len(score_coltentcount), # lower is better\n",
    "        # haven't added score_coltentvarcount\n",
    "        sum(score_colttuicount)/len(score_colttuicount), # lower is better\n",
    "        # haven't added score_colttuivarcount\n",
    "        sum(score_colpposcount)/len(score_colpposcount), # lower is better\n",
    "        sum(score_coltposcount)/len(score_coltposcount), # lower is better\n",
    "        # haven't added score_coltposvarcount\n",
    "        sum(score_colrepresent)/len(score_colrepresent), # higher is better\n",
    "        # haven't added score_colalltokens\n",
    "        0,#scoreRowAlignment(align_df, align_df.loc[[5130]]), # higher is better\n",
    "        score_termcolcount, #  lower is better\n",
    "        scoreRowLayoutCount(align_df), # lower is better\n",
    "    ])\n",
    "    # weight and sum up the score (higher total score is better)\n",
    "    score_direction = np.array([-1, -1, -1, -1, -1, -1, -1, -1,  1,  1, -1, -1])\n",
    "    score_weights   = np.array([ 0,  0, 10,  0,  0,  0,  0,  0,  0, 0., 15,  0])\n",
    "    singlescore = np.dot(np.multiply(score_weights, score_direction), scores)\n",
    "    colrelevance_represent = [r/sum(score_colrepresent) for r in score_colrepresent]\n",
    "    colrelevance_numtokens = [r/sum(score_colalltokens) for r in score_colalltokens]\n",
    "    # collect the raw stats as a displayable df\n",
    "    rawscores = pd.DataFrame([\n",
    "        score_colptxtembed,\n",
    "        score_coltextcount,\n",
    "        score_coltokncount,\n",
    "        score_coltentcount,\n",
    "        score_coltentvarcount,\n",
    "        score_colttuicount,\n",
    "        score_colttuivarcount,\n",
    "        score_colpposcount,\n",
    "        score_coltposcount,\n",
    "        score_coltposvarcount,\n",
    "        score_colrepresent,\n",
    "        colrelevance_represent,\n",
    "        score_colalltokens,\n",
    "        colrelevance_numtokens,\n",
    "    ], index=[\n",
    "        'embed variance',\n",
    "        'unique texts',\n",
    "        'unique tokens',\n",
    "        'unique entity',\n",
    "        'unique entity (var)',\n",
    "        'unique entity TUI',\n",
    "        'unique entity TUI (var)',\n",
    "        'unique phrase pos', \n",
    "        'unique token pos', \n",
    "        'unique token pos (var)', \n",
    "        'fract rows filled',\n",
    "        'relevance1 (rowsfilled)',\n",
    "        'num tokens',\n",
    "        'relevance2 (numtokens)',\n",
    "    ])\n",
    "    return singlescore, scores, rawscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alignment_being_scored = alignment_wordsonly\n",
    "# singlescore, scores, rawscores = tempScoreVectorDetail(\n",
    "#     alignment_being_scored\n",
    "# )\n",
    "# score_direction = np.array([-1, -1, -1, -1, -1, -1, -1, -1,  1,  1, -1, -1])\n",
    "# score_weights   = np.array([ 0,  0, 10,  0,  0,  0,  0,  0,  0, 0., 15,  0])\n",
    "# singlescore = np.dot(np.multiply(score_weights, score_direction), scores)\n",
    "# singlescore\n",
    "# scores\n",
    "# pd.DataFrame([str(s) for s in scores]).loc[[0, 8, 9, 10]]\n",
    "# alignment_detail = extractTup(alignment_being_scored, tup_i='segment').sort_index()\n",
    "# alignment_detail.append(rawscores.rename(columns=dict(zip(rawscores.columns, alignment_detail.columns))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Live update score and check how score components respond to changes in an alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alignment_being_scored = read_alignment_from_sheetstring_file('interactive_input/alignment')\n",
    "# singlescore, scores, rawscores = tempScoreVectorDetail(\n",
    "#     alignment_being_scored\n",
    "# )\n",
    "# score_direction = np.array([-1, -1, -1, -1, -1, -1, -1, -1,  1,  1, -1, -1])\n",
    "# score_weights   = np.array([ 0,  0, 10,  0,  0,  0,  0,  0,  0, 0., 15,  0])\n",
    "# singlescore = np.dot(np.multiply(score_weights, score_direction), scores)\n",
    "# singlescore\n",
    "# # scores\n",
    "# rawspreadscores = pd.DataFrame([str(s) for s in scores]).iloc[[0, -3, -2]]\n",
    "# rawspreadscores.index = ['colcount', 'row-alignment', 'termcolcount']\n",
    "# rawspreadscores.rename(columns={0:'aggregate'}, inplace=True)\n",
    "# # rawspreadscores\n",
    "# alignment_detail = extractTup(alignment_being_scored, tup_i='segment').sort_index()\n",
    "# rawscores = rawscores.rename(columns=dict(zip(rawscores.columns, alignment_detail.columns)))\n",
    "# rawscores = rawscores.loc[[\n",
    "#     'embed variance', 'unique texts', 'unique tokens', 'unique tokens (var)',\n",
    "#     'unique entity', 'unique entity (var)', 'unique entity TUI', 'unique entity TUI (var)', \n",
    "#     'unique token pos', 'unique token pos (var)', \n",
    "#     'fract rows filled', 'relevance1 (rowsfilled)', \n",
    "#     'num tokens', 'relevance2 (numtokens)']]\n",
    "# rawscores.insert(0, column='aggregate', value=['']*(len(rawscores.index)))\n",
    "# scoretable = rawscores.append(rawspreadscores).replace(np.nan, '', regex=True)\n",
    "# scoretable\n",
    "# alignment_detail.append(scoretable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def evaluate_test_case(test_case, weights=[0.2, 0.2, 1, 0, 0, 0], debug_print=False):\n",
    "    # Read in A and B alignments\n",
    "    align_df_a = read_alignment_from_jsondict_file(f'testcases/{test_case}/a.json')\n",
    "    align_df_b = read_alignment_from_jsondict_file(f'testcases/{test_case}/b.json')\n",
    "\n",
    "    # Read in parameters\n",
    "    with open(f'testcases/{test_case}/params.yml', 'r') as f:\n",
    "        params = json.load(f)\n",
    "\n",
    "    # Get the maximum column count that we're working with (this is used for a score)\n",
    "    max_row_length = params['max_row_length']\n",
    "\n",
    "    singlescore_a, components_a, rawscores_a = scoreAlignment(\n",
    "        align_df_a, \n",
    "        spacy_model=sp,\n",
    "        scispacy_model=scisp, scispacy_linker=linker,\n",
    "        embed_model=fasttext,\n",
    "        max_row_length=max_row_length, \n",
    "#         weight_components=np.array(weights)\n",
    "    )\n",
    "    singlescore_b, components_b, rawscores_b = scoreAlignment(\n",
    "        align_df_b, \n",
    "        spacy_model=sp,\n",
    "        scispacy_model=scisp, scispacy_linker=linker,\n",
    "        embed_model=fasttext,\n",
    "        max_row_length=max_row_length, \n",
    "#         weight_components=np.array(weights)\n",
    "    )\n",
    "\n",
    "    if debug_print:\n",
    "        print('=== TEST CASE:', test_case, '===')\n",
    "        print(f'Result: {singlescore_b - singlescore_a:.5f}')\n",
    "        print(f'(Raw scores: {singlescore_a:.5f} , {singlescore_b:.5f} )')\n",
    "    \n",
    "    return singlescore_b - singlescore_a, test_case, singlescore_a, singlescore_b, components_a, components_b, rawscores_a, rawscores_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "\n",
    "# results = []\n",
    "# for test_case in sorted(os.listdir(f'testcases/')):\n",
    "# #     results.append(evaluate_test_case(test_case, weights=[0.2, 0.2, 1, 0, 0, 0], debug_print=False))\n",
    "#     results.append(evaluate_test_case(test_case, weights=[0.2, 0.2, 1, 0, 0, 0], debug_print=False))\n",
    "\n",
    "# # # check again what the layout of each test result is\n",
    "# # print(results[0])\n",
    "\n",
    "# # define the test case groups and how to order them\n",
    "# categories = ['basic-txtshift', 'basic-colcreat', 'basic-colmerge', 'basic-holistic']\n",
    "\n",
    "# def alias_testname(testname):\n",
    "#     testname = testname.split('-')\n",
    "#     return testname[0][0]+'-'+testname[1]+'-'+testname[2]\n",
    "# results_mapping = dict([(r[1], (r[0], r[2], r[3], r[4], r[5], r[6], r[7])) for r in results])\n",
    "\n",
    "# # define templating / \"ideal metric\" scores\n",
    "# category_counts = [len([r for r in results_mapping if (cname in r)]) for cname in categories]\n",
    "# testnames = [[r[1] for r in results if (category_name in r[1])] for category_name in categories]\n",
    "# testnames = [b for a in testnames for b in sorted(a)]\n",
    "# # pd.DataFrame([[alias_testname(n) for n in testnames]])\n",
    "# # pd.DataFrame([category_counts + [''] + ['specific scores go here']])\n",
    "\n",
    "# # extract metric-specific performance\n",
    "# category_counts = [len([r for r in results_mapping if (cname in r) and (results_mapping[r][0]>0)]) for cname in categories]\n",
    "# scores = [results_mapping[tname][0] for tname in testnames]\n",
    "# pd.DataFrame([category_counts + [''] + scores])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for tname in testnames:\n",
    "#     print('====================')\n",
    "#     print(tname + ' : ' + str(results_mapping[tname][0]))\n",
    "#     print(results_mapping[tname][1])\n",
    "#     print(results_mapping[tname][3])\n",
    "#     extractTup(read_alignment_from_jsondict_file(f'testcases/{tname}/a.json'), tup_i='segment').append(results_mapping[tname][5])\n",
    "#     print(results_mapping[tname][2])\n",
    "#     print(results_mapping[tname][4])\n",
    "#     extractTup(read_alignment_from_jsondict_file(f'testcases/{tname}/b.json'), tup_i='segment').append(results_mapping[tname][6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alignment state exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### alignment state space search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### RANDOM WALK ALIGNMENT SPACE SEARCH\n",
    "# At each step, either:\n",
    "# 1. Greedy step\n",
    "# 2. Random step\n",
    "# 3. Random restart? - currently not included.\n",
    "\n",
    "import random\n",
    "\n",
    "def alignmentStateSearch(\n",
    "        alignment_file='interactive_input/alignment', \n",
    "        default_score_weighting=[0.2, 0.2, 1, 0, 0, 0], \n",
    "        debug_print=False,\n",
    "        default_step_moves=[('greedy', 1), ('randomwalk', 1)], \n",
    "        default_num_steps=1000,\n",
    "        default_greedy_cutoff=2,\n",
    "    ):\n",
    "    # Create the datastructure for output!\n",
    "    # the ith element of each array: in step i (where 0 is the input / file reading step), \n",
    "    # we performed output_alignmentop[i] operation\n",
    "    # as chosen by output_alignmentopmode[i] type of stochastic action (e.g. greedy, randomwalk...)\n",
    "    # out of the entire list of output_alignmentopset[i] operations\n",
    "    # to get output_alignmentstate[i] alignment table state\n",
    "    # which has a score of output_alignmentscore[i] as scored by the function we used when performing the search\n",
    "    # finally, output_hyperparams is a dict containing the hyperparameters we used in the search\n",
    "    # e.g. (step count, greedy cutoff, stochastic greedy/random balance, etc)\n",
    "    output_alignmentstate = []\n",
    "    output_alignmentop = [('beginning')]\n",
    "    output_alignmentopset = [[('beginning')]]\n",
    "    output_alignmentopmode = ['beginning']\n",
    "    output_alignmentscore = []\n",
    "    output_alignmentscorecomponents = []\n",
    "    output_alignmentscoreraw = []\n",
    "    output_hyperparams = {}\n",
    "    \n",
    "    # Read in our manually created start alignment\n",
    "    # TODO this could improve... for now just attempt loading in the JSON format, then fallback to sheetstring\n",
    "    try:\n",
    "        align_df = read_alignment_from_jsondict_file(alignment_file)\n",
    "    except:\n",
    "        align_df = read_alignment_from_sheetstring_file(alignment_file)\n",
    "\n",
    "    # Get the maximum column count that we're working with (this is used for a score)\n",
    "    max_row_length = max([len([e[0] for e in align_df.loc[i] if len(e[0])!=0]) for i in align_df.index])\n",
    "\n",
    "    # define hyperparameters of the random walk and search process\n",
    "    NUM_STEPS = default_num_steps\n",
    "    STEP_MOVES = default_step_moves\n",
    "    GREEDY_CUTOFF = default_greedy_cutoff\n",
    "    SCORE_WEIGHTING = default_score_weighting\n",
    "    # and save the hyperparameters\n",
    "    output_hyperparams['NUM_STEPS'] = NUM_STEPS\n",
    "    output_hyperparams['STEP_MOVES'] = STEP_MOVES\n",
    "    output_hyperparams['GREEDY_CUTOFF'] = GREEDY_CUTOFF\n",
    "    output_hyperparams['SCORE_WEIGHTING'] = SCORE_WEIGHTING\n",
    "\n",
    "    # add the preview / state at the beginning of the search\n",
    "    output_alignmentstate.append(align_df.sort_index())\n",
    "    singlescore, components, rawscores = scoreAlignment(\n",
    "        align_df, \n",
    "        spacy_model=sp,\n",
    "        scispacy_model=scisp, scispacy_linker=linker,\n",
    "        embed_model=fasttext,\n",
    "        max_row_length=max_row_length, \n",
    "        weight_components=np.array(SCORE_WEIGHTING)\n",
    "    )\n",
    "    output_alignmentscore.append(singlescore)\n",
    "    output_alignmentscorecomponents.append(components)\n",
    "    output_alignmentscoreraw.append(rawscores)\n",
    "    \n",
    "    # normalize probabilities for step_moves\n",
    "    sum_prob = sum([e[1] for e in STEP_MOVES])\n",
    "    STEP_MOVES = [(e[0], e[1]/sum_prob) for e in STEP_MOVES]\n",
    "    # transform STEP_MOVES into something that's easier for me to break down and de-probabilify\n",
    "    temp_runningsum = 0\n",
    "    STEP_MOVES_DIST = []\n",
    "    for e in STEP_MOVES:\n",
    "        STEP_MOVES_DIST.append((e[0], temp_runningsum+e[1]))\n",
    "        temp_runningsum += e[1]\n",
    "    # set up trans-loop variables\n",
    "    running_progress = []\n",
    "    current_score = scoreAlignment(\n",
    "        align_df, \n",
    "        spacy_model=sp,\n",
    "        scispacy_model=scisp, scispacy_linker=linker,\n",
    "        embed_model=fasttext, \n",
    "        max_row_length=max_row_length, \n",
    "        weight_components=np.array(SCORE_WEIGHTING)\n",
    "    )\n",
    "    \n",
    "    # perform the search!\n",
    "    i = 0\n",
    "    greedy_stuck = 0\n",
    "    while (i < NUM_STEPS) and (greedy_stuck < GREEDY_CUTOFF):\n",
    "        # Define/ build up the list of what operations we can make right now\n",
    "        # TODO refine this so operations are fairly represented ... ?\n",
    "        valid_operations = []\n",
    "        valid_operations += [('none', 0)]\n",
    "#         valid_operations += [('split', e, False) for e in align_df.columns]\n",
    "#         valid_operations += [('split', e, True) for e in align_df.columns]\n",
    "#         valid_operations += [('merge', e) for e in align_df.columns[:-1]]\n",
    "        # be overeager with what is 'valid' for shift, calculating these ahead of time is sort of a pain\n",
    "        for col_i in range(len(align_df.columns)):\n",
    "            # get all valid clumps of rows in the column\n",
    "            col_texts = [e for e in zip([e[0] for e in align_df[align_df.columns[col_i]]], align_df.index) if len(e[0])!=0]\n",
    "            row_clumps = {}\n",
    "            for col_word in set([e[0] for e in col_texts]):\n",
    "                row_clumps[col_word] = [e[1] for e in col_texts if e[0]==col_word]\n",
    "            if len(row_clumps)>0: # 1: # only cannot be done with other operations\n",
    "                # don't do a shift if doing any shifting in this column would be identical to a merge...\n",
    "                for row_clump_word in row_clumps:\n",
    "                    for distance in range(-1 * len(align_df.columns), len(align_df.columns)): # [-1, 1]:\n",
    "                        if distance != 0 and canShiftCells(align_df, row_clumps[row_clump_word], align_df.columns[col_i], distance, 1):\n",
    "                            valid_operations += [\n",
    "                                ('shift', row_clumps[row_clump_word], align_df.columns[col_i], distance, 1)\n",
    "                            ]\n",
    "        output_alignmentopset.append(valid_operations)\n",
    "        # pull move from the move prob distribution\n",
    "        move = random.uniform(0, 1)\n",
    "        move = [e for e in STEP_MOVES_DIST if e[1]>=move][0][0] # de-probabilify the selected move\n",
    "        output_alignmentopmode.append(move)\n",
    "        if debug_print:\n",
    "            print(f'step {i}: {move}')\n",
    "            print(f'    # valid ops: {len(valid_operations)}')\n",
    "        # run through all of the operations and calculate what their moves would be\n",
    "        candidates = []\n",
    "        operation_i = 1\n",
    "        for selected_operation in valid_operations:\n",
    "            if selected_operation[0]=='split':\n",
    "                operated = splitCol(align_df, selected_operation[1], right_align=selected_operation[2])\n",
    "            elif selected_operation[0]=='merge':\n",
    "                operated = mergeCol(align_df, selected_operation[1])\n",
    "            elif selected_operation[0]=='shift':\n",
    "                operated = shiftCells(\n",
    "                    align_df, \n",
    "                    selected_operation[1], \n",
    "                    selected_operation[2], \n",
    "                    selected_operation[3], \n",
    "                    shift_size=selected_operation[4], \n",
    "                )\n",
    "            elif selected_operation[0]=='none':\n",
    "                operated = align_df\n",
    "            else:\n",
    "                raise ValueError('uh oh, undefined operation')\n",
    "            singlescore, components, rawscores = scoreAlignment(\n",
    "                operated, \n",
    "                spacy_model=sp,\n",
    "                scispacy_model=scisp, scispacy_linker=linker,\n",
    "                embed_model=fasttext,\n",
    "                max_row_length=max_row_length, \n",
    "                weight_components=np.array(SCORE_WEIGHTING)\n",
    "            )\n",
    "            candidates.append((operated, singlescore, selected_operation))\n",
    "            if debug_print:\n",
    "                print(f'\\r    completed calculating operation#{operation_i}', end='', flush=True)\n",
    "            operation_i += 1\n",
    "        if debug_print:\n",
    "            print()\n",
    "        # sort all operations by score descending\n",
    "        candidates.sort(key=lambda x: -1 * x[1])\n",
    "        # keep track of if it's still possible to improve from here\n",
    "        if candidates[0][2][0]=='none':\n",
    "            # we would run greedy=none\n",
    "            if debug_print:\n",
    "                print(f'    greedy=none: {greedy_stuck} times in a row')\n",
    "            greedy_stuck += 1\n",
    "        else:\n",
    "            greedy_stuck = 0\n",
    "        # If we haven't hit the quit condition, make the alignment search step, depending on greedy or random...\n",
    "        if (greedy_stuck < GREEDY_CUTOFF):\n",
    "            if move == 'greedy':\n",
    "                # Make the change that results in best score!\n",
    "                align_df = candidates[0][0]\n",
    "                output_alignmentop.append(candidates[0][2])\n",
    "            elif move == 'randomwalk':\n",
    "                selected = random.randint(0, len(candidates)-1)\n",
    "                align_df = candidates[selected][0]\n",
    "                output_alignmentop.append(candidates[selected][2])\n",
    "            else:\n",
    "                raise ValueError('uh oh, undefined search move/mode')\n",
    "        else:\n",
    "            output_alignmentop.append(('ending-nogreedymove'))\n",
    "            if debug_print:\n",
    "                print(f'    hit quit condition (greedy move = None for last {GREEDY_CUTOFF} steps); not moving')\n",
    "        i += 1\n",
    "        singlescore, components, rawscores = scoreAlignment(\n",
    "            align_df, \n",
    "            spacy_model=sp,\n",
    "            scispacy_model=scisp, scispacy_linker=linker,\n",
    "            embed_model=fasttext,\n",
    "            max_row_length=max_row_length, \n",
    "            weight_components=np.array(SCORE_WEIGHTING)\n",
    "        )\n",
    "        output_alignmentstate.append(align_df.sort_index())\n",
    "        output_alignmentscore.append(singlescore)\n",
    "        output_alignmentscorecomponents.append(components)\n",
    "        output_alignmentscoreraw.append(rawscores)\n",
    "    \n",
    "    return output_alignmentstate, output_alignmentop, output_alignmentopset, output_alignmentopmode, \\\n",
    "        output_alignmentscore, output_alignmentscorecomponents, output_alignmentscoreraw, output_hyperparams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### do multiple searches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "\n",
    "# nameprefix = 'row4score-'\n",
    "\n",
    "# for align_name in ['a']:#, 'b', 'c', 'd', 'e']:\n",
    "#     temp_search = alignmentStateSearch(\n",
    "#         alignment_file='interactive_input/alignment',\n",
    "#         default_score_weighting=[0, 0, 1, 0, 0, 0], \n",
    "#         default_step_moves=[('greedy', 1), ('randomwalk', 1)],\n",
    "#         default_num_steps=5,\n",
    "#         debug_print=True\n",
    "#     )\n",
    "\n",
    "#     pickle.dump(temp_search, open(f'temp/search_temp_{nameprefix}{align_name}.pkl', 'wb'))\n",
    "    \n",
    "# #     temp_search = pickle.load(open(f'temp/search_temp_search_{nameprefix}{align_name}.pkl', 'rb'))\n",
    "# #     output_alignmentstate, output_alignmentop, output_alignmentopset, output_alignmentopmode, output_alignmentscore, \\\n",
    "# #             output_alignmentscorecomponents, output_alignmentscoreraw, output_hyperparams = temp_search\n",
    "\n",
    "# #     print(output_alignmentscore)\n",
    "\n",
    "# # other sample searches\n",
    "# # alignmentStateSearch(alignment_file='interactive_input/alignment_nopunct') # \"nice alignment (manually removed punctuation)\"\n",
    "# # alignmentStateSearch(alignment_file='interactive_input/alignment_handmade') # \"handmade nice alignment\"\n",
    "# # alignmentStateSearch(alignment_file='interactive_input/alignment_diabetes') # \"nice alignment (different topic)\"\n",
    "# # alignmentStateSearch(alignment_file='interactive_input/alignment_hyphenmerge') # \"nice alignment (merged hyphen phrases)\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### manually tweak alignment and see where it leads us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# spreadsheetFormat(output_alignmentstate[13])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# temp_search_manually_adjusted = alignmentStateSearch(\n",
    "#     alignment_file='interactive_input/manuallyadjusted', \n",
    "#     default_score_weighting=[0, 0, 0, 0, 0, 1], \n",
    "#     debug_print=True\n",
    "# )\n",
    "# output_alignmentstate, output_alignmentop, output_alignmentopset, output_alignmentopmode, output_alignmentscore, \\\n",
    "#         output_alignmentscorecomponents, output_alignmentscoreraw, output_hyperparams = temp_search_manually_adjusted\n",
    "\n",
    "# print('===   assert sanity   ===')\n",
    "# print()\n",
    "\n",
    "# print('all of these should be the same:')\n",
    "# print(len(output_alignmentstate), len(output_alignmentop), len(output_alignmentopset), len(output_alignmentopmode), len(output_alignmentscore))\n",
    "\n",
    "# print()\n",
    "# print('=== search algorithm! ===')\n",
    "# print()\n",
    "\n",
    "# output_hyperparams\n",
    "# print()\n",
    "# print(f'score components: [score_numcolumns     score_colptxtembed     score_coltokncount     score_colttuivarcount]')\n",
    "# print()\n",
    "# for i in range(len(output_alignmentop)):\n",
    "#     print(f'step {i}: {output_alignmentopmode[i]}')\n",
    "#     print(f'    performed op: {output_alignmentop[i]}, out of {len(output_alignmentopset[i])} valid op(s)')\n",
    "#     print(f'        ops={output_alignmentopset[i]}')\n",
    "#     print(f'    result score: {output_alignmentscore[i]}')\n",
    "#     print(f'    components: {output_alignmentscorecomponents[i]}')\n",
    "# #     output_alignmentstate[i].append(output_alignmentscoreraw[i])\n",
    "#     extractTup(output_alignmentstate[i], tup_i='segment').append(output_alignmentscoreraw[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
